# V100 32GB Ã— 2 - ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ¯ ì¤€ë¹„ ì™„ë£Œ!

V100 32GB Ã— 2ì¥ì— ìµœì í™”ëœ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“¦ ìƒì„±ëœ íŒŒì¼

```
Wan2.2/
â”œâ”€â”€ lora_finetuning/configs/
â”‚   â””â”€â”€ v100_2gpu_config.py          # V100 ìµœì í™” ì„¤ì •
â”‚
â”œâ”€â”€ preprocessed_data/
â”‚   â”œâ”€â”€ all_train.csv (179,994ê°œ)    # ì „ì²´ í•™ìŠµ ë°ì´í„°
â”‚   â”œâ”€â”€ all_val.csv (20,000ê°œ)       # ì „ì²´ ê²€ì¦ ë°ì´í„°
â”‚   â””â”€â”€ test_100.csv (100ê°œ)         # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚
â”œâ”€â”€ train_v100.sh                     # ì „ì²´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ train_v100_test.sh                # ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ create_test_dataset.py            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
â”‚
â”œâ”€â”€ validate_data_quality.py          # í’ˆì§ˆ ê²€ì¦
â”œâ”€â”€ inspect_samples.py                # ì‹œê°ì  ê²€ì¦
â”‚
â””â”€â”€ ë¬¸ì„œ/
    â”œâ”€â”€ V100_SETUP_GUIDE.md           # ìƒì„¸ ê°€ì´ë“œ
    â””â”€â”€ V100_NEXT_STEPS.md            # ì´ íŒŒì¼
```

## ğŸš€ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„

### ë‹¨ê³„ 1: í™˜ê²½ í™•ì¸ (5ë¶„) âœ…

```bash
# GPU í™•ì¸
nvidia-smi

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source .venv/bin/activate

# ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install bitsandbytes

# PyTorch CUDA í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

### ë‹¨ê³„ 2: ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ (í•„ìˆ˜) âš ï¸

```bash
# Wan2.2 T2V-A14B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (~40GB)
huggingface-cli download Wan-AI/Wan2.2-T2V-A14B --local-dir ./Wan2.2-T2V-A14B

# ë‹¤ìš´ë¡œë“œ í™•ì¸
ls -lh Wan2.2-T2V-A14B/
```

### ë‹¨ê³„ 3: ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ (30-60ë¶„) âš ï¸

**âš ï¸ ì¤‘ìš”: ì „ì²´ í•™ìŠµ ì „ ë°˜ë“œì‹œ ì´ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!**

```bash
# ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
bash train_v100_test.sh
```

**ë˜ëŠ” ìˆ˜ë™ ì‹¤í–‰:**

```bash
python lora_finetuning/train_lora.py \
  --train_csv ./preprocessed_data/test_100.csv \
  --val_csv ./preprocessed_data/test_100.csv \
  --ckpt_dir ./Wan2.2-T2V-A14B \
  --output_dir ./lora_checkpoints_v100_test \
  --num_epochs 5 \
  --batch_size 1 \
  --gradient_accumulation_steps 4 \
  --save_steps 50
```

**í™•ì¸ ì‚¬í•­:**

âœ… **Lossê°€ ê°ì†Œí•˜ëŠ”ê°€?**
```
Epoch 1: Loss ~0.5
Epoch 3: Loss ~0.1
Epoch 5: Loss ~0.01 â† ì´ë ‡ê²Œ ë–¨ì–´ì ¸ì•¼ ì„±ê³µ!
```

âœ… **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**
```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ
watch -n 1 nvidia-smi

# ëª©í‘œ: ê° GPU 28-30GB/32GB (ì•ˆì „)
```

âœ… **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**
```bash
ls -lh lora_checkpoints_v100_test/
# checkpoint_epoch_*.pt íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•¨
```

### ë‹¨ê³„ 4: ì „ì²´ í•™ìŠµ (5-7ì¼) â³

ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´ ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ:

```bash
# ì „ì²´ í•™ìŠµ ì‹œì‘
bash train_v100.sh

# ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup bash train_v100.sh > train.log 2>&1 &

# ë¡œê·¸ í™•ì¸
tail -f train.log
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ GPU ëª¨ë‹ˆí„°ë§

```bash
# í„°ë¯¸ë„ 1: í•™ìŠµ ì‹¤í–‰
bash train_v100.sh

# í„°ë¯¸ë„ 2: GPU ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

### Loss ì¶”ì 

```bash
# Loss í™•ì¸
grep "Loss:" lora_checkpoints_v100/train.log

# ë˜ëŠ” ì‹¤ì‹œê°„
tail -f lora_checkpoints_v100/train.log | grep Loss
```

## ğŸ“ V100 ìµœì í™” ìš”ì•½

### A100 ëŒ€ë¹„ ë³€ê²½ì‚¬í•­

| í•­ëª© | A100 80GB Ã— 8 | V100 32GB Ã— 2 |
|------|---------------|---------------|
| LoRA Rank | 32 | **16** â¬‡ï¸ |
| Frame Num | 81 | **49** â¬‡ï¸ |
| Gradient Accum | 4 | **16** â¬†ï¸ |
| Caption Length | 512 | **256** â¬‡ï¸ |
| T5 Offload | No | **Yes** |
| VAE Offload | No | **Yes** |
| Optimizer | AdamW | **AdamW 8bit** |
| **Effective Batch** | **32** | **32** âœ… |

### ë©”ëª¨ë¦¬ ì‚¬ìš© ì˜ˆìƒ

```
GPUë‹¹ ë©”ëª¨ë¦¬ (32GB):
â”œâ”€â”€ Base Model: ~20GB
â”œâ”€â”€ LoRA (r=16): ~2GB
â”œâ”€â”€ Gradients: ~4GB
â”œâ”€â”€ Optimizer (8bit): ~2GB
â”œâ”€â”€ Activations: ~2GB
â””â”€â”€ ì—¬ìœ : ~2GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~30GB/32GB âœ…
```

## âš ï¸ ë¬¸ì œ í•´ê²°

### OOM (Out of Memory)

```bash
# 1. í”„ë ˆì„ ìˆ˜ ì¤„ì´ê¸°
# v100_2gpu_config.py ìˆ˜ì •:
frame_num = 33  # 49 â†’ 33

# 2. LoRA rank ì¤„ì´ê¸°
lora_r = 8  # 16 â†’ 8

# 3. GPU ì´ˆê¸°í™”
nvidia-smi --gpu-reset
```

### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

```bash
# ì›Œì»¤ ìˆ˜ ëŠ˜ë¦¬ê¸° (v100_2gpu_config.py)
num_workers = 4  # 2 â†’ 4

# ë°ì´í„° ë¡œë”© ë³‘ëª© í™•ì¸
# â†’ í•´ìƒë„ ë³€í™˜ ì „ì²˜ë¦¬ ê¶Œì¥
```

### bitsandbytes ì˜¤ë¥˜

```bash
pip uninstall bitsandbytes
pip install bitsandbytes==0.43.0 --no-cache-dir
```

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

### ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ (100 ìƒ˜í”Œ, 5 epochs)
- â±ï¸ ì‹œê°„: 30-60ë¶„
- ğŸ’¾ ë©”ëª¨ë¦¬: ~30GB/GPU
- ğŸ“‰ Loss: 0.5 â†’ 0.01
- âœ… ëª©í‘œ: ì™„ì „ ê³¼ì í•© (ëª¨ë¸ì´ ì‘ë™í•¨ì„ í™•ì¸)

### ì „ì²´ í•™ìŠµ (179,994 ìƒ˜í”Œ, 3 epochs)
- â±ï¸ ì‹œê°„: 5-7ì¼
- ğŸ’¾ ë©”ëª¨ë¦¬: ~30GB/GPU
- ğŸ“‰ Loss: Epoch 1 (~0.15) â†’ Epoch 3 (~0.03)
- ğŸ’¾ ì²´í¬í¬ì¸íŠ¸: ~500MB/epoch

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹œì‘ ì „ í™•ì¸:

- [ ] GPU 2ì¥ ì¸ì‹ (`nvidia-smi`)
- [ ] bitsandbytes ì„¤ì¹˜ (`pip list | grep bitsandbytes`)
- [ ] ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ (`ls Wan2.2-T2V-A14B/`)
- [ ] í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (`ls preprocessed_data/test_100.csv`)
- [ ] ë””ìŠ¤í¬ ê³µê°„ (ìµœì†Œ 100GB ì—¬ìœ )

ì‹¤í–‰:

- [ ] ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ ì„±ê³µ (Loss < 0.1)
- [ ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (< 30GB)
- [ ] ì „ì²´ í•™ìŠµ ì‹œì‘
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •

## ğŸ¯ í˜„ì¬ ìƒíƒœ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ                    â”‚
â”‚ âœ… í’ˆì§ˆ ê²€ì¦ ë„êµ¬ ì™„ì„±                   â”‚
â”‚ âœ… V100 ìµœì í™” ì„¤ì • ì™„ë£Œ                 â”‚
â”‚ âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (100ê°œ)            â”‚
â”‚ âœ… í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„                    â”‚
â”‚                                          â”‚
â”‚ âš ï¸ ë‹¤ìŒ: ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰             â”‚
â”‚ â¬œ ëŒ€ê¸°: ì „ì²´ í•™ìŠµ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ ì§€ê¸ˆ ë°”ë¡œ ì‹¤í–‰!

```bash
# 1. ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ
huggingface-cli download Wan-AI/Wan2.2-T2V-A14B --local-dir ./Wan2.2-T2V-A14B

# 2. ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸
bash train_v100_test.sh

# 3. ê²°ê³¼ í™•ì¸ í›„ ì „ì²´ í•™ìŠµ
bash train_v100.sh
```

**ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ! í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”!** ğŸ‰
