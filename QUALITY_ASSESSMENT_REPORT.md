# ğŸ“‹ ë°ì´í„°ì…‹ í’ˆì§ˆ í‰ê°€ ë¦¬í¬íŠ¸

**í‰ê°€ ì¼ì‹œ**: 2025ë…„ 11ì›” 7ì¼
**í‰ê°€ ê¸°ì¤€**: RAPA 2025 ë°©ì†¡ì˜ìƒ AI í•™ìŠµìš© ë°ì´í„° í’ˆì§ˆì§€í‘œ ê¸°ì¤€ì„œ
**ë°ì´í„°ì…‹**: ë°©ì†¡ì˜ìƒ AI í•™ìŠµìš© ë¹„ë””ì˜¤ ìº¡ì…”ë‹ ë°ì´í„°ì…‹
**ì´ ìƒ˜í”Œ ìˆ˜**: 199,941ê°œ (ë¹„ë””ì˜¤: 99,947 / ì´ë¯¸ì§€: 99,994)

---

## ğŸ“Š ì¢…í•© í‰ê°€ ê²°ê³¼

| í’ˆì§ˆ íŠ¹ì„± | ëª©í‘œ | í˜„ì¬ ìƒíƒœ | ë‹¬ì„±ë¥  | ë“±ê¸‰ |
|----------|------|----------|--------|------|
| **1. í˜•ì‹ì„±** | 99% ì´ìƒ | âŒ ë¯¸ì¸¡ì • | 0% | **F** |
| **2. ë‹¤ì–‘ì„±(í†µê³„)** | ë¶„í¬ í™•ì¸ | âš ï¸ ì¼ë¶€ ë‹¬ì„± | 60% | **C** |
| **3. ë‹¤ì–‘ì„±(ìš”ê±´)** | ìµœì†Œê°’ ì¶©ì¡± | âš ï¸ ì¼ë¶€ ë‹¬ì„± | 50% | **D** |
| **4. êµ¬ë¬¸ ì •í™•ì„±** | 99.5% ì´ìƒ | âŒ ë¯¸ì¸¡ì • | 0% | **F** |
| **5. ì˜ë¯¸ ì •í™•ì„±** | 90% ì´ìƒ | âŒ ë¯¸ì¸¡ì • | 0% | **F** |
| **6. ìœ íš¨ì„±** | CLIP â‰¥0.3, FVD â‰¤1140 | âŒ **ë¯¸ì¸¡ì •** | 0% | **F** |

### ğŸ¯ ì¢…í•© ì ìˆ˜: **30/100ì  (Fë“±ê¸‰)**

**íŒì •**: âŒ **ì¬ì‘ì—… í•„ìš”**

---

## ğŸ“ˆ í’ˆì§ˆ íŠ¹ì„±ë³„ ìƒì„¸ í‰ê°€

### 1. í˜•ì‹ì„± (Formality) - âŒ Fë“±ê¸‰

#### ëª©í‘œ
- íŒŒì¼ ìœ íš¨ì„±: 99% ì´ìƒ
- íŒŒì¼ í¬ë§· ì í•©ì„±: 99% ì´ìƒ
- íŒŒì¼ ì†ì„± ì í•©ì„±: 99% ì´ìƒ

#### í˜„ì¬ ìƒíƒœ
âŒ **ê²€ì¦ ë¯¸ì‹¤ì‹œ**

#### ë¬¸ì œì 
1. **íŒŒì¼ ìœ íš¨ì„± ë¯¸ê²€ì¦**: ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì•ˆ ë¨
2. **íŒŒì¼ ì†ìƒ ê²€ì‚¬ ì—†ìŒ**: ë¹„ë””ì˜¤/ì´ë¯¸ì§€ íŒŒì¼ì´ ì—´ë¦¬ëŠ”ì§€ í…ŒìŠ¤íŠ¸ ì•ˆ ë¨
3. **í¬ë§· ê²€ì¦ ì—†ìŒ**: mp4, json í˜•ì‹ ì¤€ìˆ˜ ì—¬ë¶€ ë¯¸í™•ì¸
4. **ë©”íƒ€ë°ì´í„° ì •í™•ì„± ë¯¸ê²€ì¦**: í•´ìƒë„, í”„ë ˆì„ë ˆì´íŠ¸, ê¸¸ì´ ë“±ì´ ì‹¤ì œ íŒŒì¼ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ ì•ˆ ë¨

#### ê°œì„  ë°©ì•ˆ

**Phase 1: íŒŒì¼ ì¡´ì¬ ë° ìœ íš¨ì„± ê²€ì¦ (1ì¼)**
```python
# scripts/validate_file_existence.py
import os
import pandas as pd
from tqdm import tqdm

def validate_files(csv_path):
    df = pd.read_csv(csv_path)

    valid = 0
    invalid = 0
    missing = []

    for idx, row in tqdm(df.iterrows(), total=len(df)):
        file_path = row['file_path']

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_path):
            invalid += 1
            missing.append({
                'clip_id': row['clip_id'],
                'file_path': file_path,
                'issue': 'file_not_found'
            })
            continue

        # íŒŒì¼ í¬ê¸° í™•ì¸
        if os.path.getsize(file_path) == 0:
            invalid += 1
            missing.append({
                'clip_id': row['clip_id'],
                'file_path': file_path,
                'issue': 'empty_file'
            })
            continue

        valid += 1

    validity_rate = (valid / len(df)) * 100

    print(f"íŒŒì¼ ìœ íš¨ì„±: {validity_rate:.2f}%")
    print(f"ìœ íš¨: {valid:,} / ë¬´íš¨: {invalid:,}")

    # ëª©í‘œ: 99% ì´ìƒ
    if validity_rate >= 99.0:
        print("âœ… ëª©í‘œ ë‹¬ì„±")
    else:
        print(f"âŒ ëª©í‘œ ë¯¸ë‹¬ (ë¶€ì¡±: {99.0 - validity_rate:.2f}%)")

    # ë¬¸ì œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì €ì¥
    if missing:
        pd.DataFrame(missing).to_csv('missing_files.csv', index=False)

    return validity_rate

# ì‹¤í–‰
validity = validate_files('./preprocessed_data/all_train.csv')
```

**Phase 2: ë¹„ë””ì˜¤ íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ (2ì¼)**
```python
# scripts/validate_video_integrity.py
import cv2
import subprocess
import json

def check_video_integrity(video_path):
    """ë¹„ë””ì˜¤ íŒŒì¼ ì†ìƒ ì—¬ë¶€ í™•ì¸"""
    try:
        # OpenCVë¡œ ì—´ê¸° ì‹œë„
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False, "cannot_open"

        # í”„ë ˆì„ ìˆ˜ í™•ì¸
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if frame_count == 0:
            return False, "no_frames"

        # ì²« í”„ë ˆì„ ì½ê¸° ì‹œë„
        ret, frame = cap.read()
        if not ret:
            return False, "cannot_read_frame"

        cap.release()

        # ffprobeë¡œ ì½”ë± í™•ì¸
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=codec_name,width,height,r_frame_rate',
            '-of', 'json',
            video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            return False, "ffprobe_error"

        return True, "valid"

    except Exception as e:
        return False, f"exception: {str(e)}"

# ì‚¬ìš©
is_valid, issue = check_video_integrity('/path/to/video.mp4')
```

**Phase 3: ë©”íƒ€ë°ì´í„° ì •í™•ì„± ê²€ì¦ (3ì¼)**
```python
# scripts/validate_metadata_accuracy.py
import cv2
from PIL import Image

def extract_actual_metadata(file_path, media_type):
    """ì‹¤ì œ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    if media_type == 'video':
        cap = cv2.VideoCapture(file_path)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps if fps > 0 else 0
        cap.release()

        return {
            'resolution': f"{width}, {height}",
            'length': duration,
            'fps': fps
        }

    elif media_type == 'image':
        img = Image.open(file_path)
        width, height = img.size

        return {
            'resolution': f"{width}, {height}",
            'length': 0,
            'fps': 0
        }

def validate_metadata(csv_path, sample_size=1000):
    """ë©”íƒ€ë°ì´í„° ì •í™•ì„± ê²€ì¦"""
    df = pd.read_csv(csv_path).sample(n=sample_size)

    match = 0
    mismatch = []

    for idx, row in df.iterrows():
        actual = extract_actual_metadata(row['file_path'], row['media_type'])

        # í•´ìƒë„ ë¹„êµ
        if row['resolution'] != actual['resolution']:
            mismatch.append({
                'clip_id': row['clip_id'],
                'field': 'resolution',
                'expected': row['resolution'],
                'actual': actual['resolution']
            })
        # ê¸¸ì´ ë¹„êµ (ì˜¤ì°¨ Â±1ì´ˆ í—ˆìš©)
        elif abs(row['length'] - actual['length']) > 1.0:
            mismatch.append({
                'clip_id': row['clip_id'],
                'field': 'length',
                'expected': row['length'],
                'actual': actual['length']
            })
        else:
            match += 1

    accuracy = (match / sample_size) * 100
    print(f"ë©”íƒ€ë°ì´í„° ì •í™•ì„±: {accuracy:.2f}%")

    return accuracy, mismatch
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 1ì£¼ì¼
**ì˜ˆìƒ ë¹„ìš©**: V100 GPU 40ì‹œê°„ ($200~$400)

---

### 2. ë‹¤ì–‘ì„±(í†µê³„) - âš ï¸ Cë“±ê¸‰

#### ëª©í‘œ
- ì¥ë¥´ë³„ ë¶„í¬: ë¶„í¬ í™•ì¸
- ë¹„ë””ì˜¤ ê¸¸ì´ ë¶„í¬: í‰ê·  20ì´ˆ, 25ì´ˆ ì´ìƒ 2% ë¯¸ë§Œ
- ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬: ê· í˜•ì  ë¶„í¬

#### í˜„ì¬ ìƒíƒœ

**âœ… ë‹¬ì„± í•­ëª©:**
- ë¹„ë””ì˜¤ í‰ê·  ê¸¸ì´: **23.40ì´ˆ** (ëª©í‘œ: 20ì´ˆ ì´ìƒ) âœ“

**âŒ ë¯¸ë‹¬ì„± í•­ëª©:**
- 25ì´ˆ ì´ìƒ ë¹„ë””ì˜¤: **14.9%** (ëª©í‘œ: 2% ë¯¸ë§Œ) âœ—
  - **ì´ˆê³¼ë¶„**: 12.9%p (ì•½ 13,000ê°œ ë¹„ë””ì˜¤)

**âš ï¸ ê°œì„  í•„ìš”:**
- ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶ˆê· í˜•:
  - ìƒí™œ/ë¬¸í™”: 28.7% (ìµœë‹¤)
  - ë¬´í˜•ë¬¸í™”ìœ ì‚°: 1.0% (ìµœì†Œ)
  - **í¸ì°¨**: 27.7%p

#### ë¬¸ì œì 

1. **ì¥í¸ ë¹„ë””ì˜¤ ê³¼ë‹¤**: 25ì´ˆ ì´ìƒì´ 14.9%ë¡œ ëª©í‘œ(2%)ì˜ **7.5ë°°** ì´ˆê³¼
2. **ì¹´í…Œê³ ë¦¬ í¸ì¤‘**: ìƒí™œ/ë¬¸í™”ê°€ ì „ì²´ì˜ 1/3 ì°¨ì§€
3. **ì†Œìˆ˜ ì¹´í…Œê³ ë¦¬ ë¶€ì¡±**: ìœ í˜•/ë¬´í˜•ë¬¸í™”ìœ ì‚° í•©ì³ë„ 2.1%

#### ê°œì„  ë°©ì•ˆ

**Option 1: ì¥í¸ ë¹„ë””ì˜¤ íŠ¸ë¦¬ë° (ê¶Œì¥)**
```python
# scripts/trim_long_videos.py
import pandas as pd
from moviepy.editor import VideoFileClip

def trim_video(input_path, output_path, max_duration=25.0):
    """25ì´ˆ ì´ìƒ ë¹„ë””ì˜¤ë¥¼ 25ì´ˆë¡œ íŠ¸ë¦¬ë°"""
    clip = VideoFileClip(input_path)

    if clip.duration > max_duration:
        trimmed = clip.subclip(0, max_duration)
        trimmed.write_videofile(output_path, codec='libx264')
        clip.close()
        trimmed.close()
        return True

    clip.close()
    return False

# 25ì´ˆ ì´ˆê³¼ ë¹„ë””ì˜¤ ì‹ë³„
df = pd.read_csv('all_train.csv')
long_videos = df[df['length'] > 25.0]

print(f"25ì´ˆ ì´ˆê³¼ ë¹„ë””ì˜¤: {len(long_videos):,}ê°œ")
print(f"ì²˜ë¦¬ í•„ìš”: {len(long_videos) - (len(df) * 0.02):.0f}ê°œ")

# íŠ¸ë¦¬ë° ë˜ëŠ” ì œê±° ê²°ì •
# ë°©ë²• 1: 25ì´ˆë¡œ íŠ¸ë¦¬ë°
# ë°©ë²• 2: ì•„ì˜ˆ ì œê±°í•˜ê³  20~25ì´ˆ ë¹„ë””ì˜¤ë¡œ ëŒ€ì²´
```

**Option 2: ì¹´í…Œê³ ë¦¬ ë¦¬ë°¸ëŸ°ì‹±**
```python
# scripts/rebalance_categories.py
import pandas as pd

df = pd.read_csv('all_train.csv')

# ëª©í‘œ: ê° ì¹´í…Œê³ ë¦¬ ìµœì†Œ 10%, ìµœëŒ€ 20%
target_min = len(df) * 0.10
target_max = len(df) * 0.20

# ì˜¤ë²„ìƒ˜í”Œë§: ì†Œìˆ˜ ì¹´í…Œê³ ë¦¬ ì¦ê°•
minority_cats = ['ìœ í˜•ë¬¸í™”ìœ ì‚°', 'ë¬´í˜•ë¬¸í™”ìœ ì‚°', 'ì¶•ì œ']
for cat in minority_cats:
    cat_df = df[df['category'] == cat]
    shortage = target_min - len(cat_df)

    if shortage > 0:
        # ì¦ê°• í•„ìš”
        augmented = cat_df.sample(n=int(shortage), replace=True)
        df = pd.concat([df, augmented])
        print(f"{cat}: {len(cat_df)}ê°œ â†’ {target_min}ê°œ (ì¦ê°•)")

# ì–¸ë”ìƒ˜í”Œë§: ë‹¤ìˆ˜ ì¹´í…Œê³ ë¦¬ ì¶•ì†Œ
majority_cats = ['ìƒí™œ/ë¬¸í™”', 'ì—­ì‚¬/ì‚¬íšŒ']
for cat in majority_cats:
    cat_df = df[df['category'] == cat]
    excess = len(cat_df) - target_max

    if excess > 0:
        # ì¶•ì†Œ í•„ìš”
        keep = cat_df.sample(n=int(target_max))
        df = df[~df.index.isin(cat_df.index) | df.index.isin(keep.index)]
        print(f"{cat}: {len(cat_df)}ê°œ â†’ {target_max}ê°œ (ì¶•ì†Œ)")

df.to_csv('all_train_rebalanced.csv', index=False)
```

**ì˜ˆìƒ ê²°ê³¼**:
- 25ì´ˆ ì´ìƒ ë¹„ë””ì˜¤: 14.9% â†’ **1.5%** (ëª©í‘œ ë‹¬ì„±)
- ì¹´í…Œê³ ë¦¬ ìµœëŒ€/ìµœì†Œ í¸ì°¨: 27.7%p â†’ **10%p** (ê°œì„ )

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3ì¼
**ì˜ˆìƒ ë¹„ìš©**: ìŠ¤í† ë¦¬ì§€ 200GB ì¶”ê°€ ($10)

---

### 3. ë‹¤ì–‘ì„±(ìš”ê±´) - âš ï¸ Dë“±ê¸‰

#### ëª©í‘œ
- ë¹„ë””ì˜¤ ë°ì´í„° ì‹œê°„: 3,600ì‹œê°„ ì´ìƒ
- ë¹„ë””ì˜¤ ì˜ìƒ í‰ê·  ê¸¸ì´: 20ì´ˆ ì´ìƒ
- ì„¤ëª…ë¬¸ ìµœì†Œ í† í° ìˆ˜: 50í† í° ì´ìƒ
- ì„¤ëª…ë¬¸ ìµœì†Œ ë¬¸ì¥ ìˆ˜: 5ë¬¸ì¥ ì´ìƒ

#### í˜„ì¬ ìƒíƒœ

**âœ… ë‹¬ì„± í•­ëª©:**
- ë¹„ë””ì˜¤ í‰ê·  ê¸¸ì´: **23.40ì´ˆ** (ëª©í‘œ: 20ì´ˆ) âœ“

**âŒ ë¯¸ì¸¡ì • í•­ëª©:**
- ì „ì²´ ë¹„ë””ì˜¤ ì‹œê°„: **ë¯¸ê³„ì‚°**
- ìº¡ì…˜ í† í° ìˆ˜: **ë¯¸ì¸¡ì •**
- ìº¡ì…˜ ë¬¸ì¥ ìˆ˜: **ë¯¸ì¸¡ì •**

**âš ï¸ ì˜ˆìƒ ë¬¸ì œ:**
- ìº¡ì…˜ í‰ê·  ê¸¸ì´: 450.7ì (ë§¤ìš° ê¹€)
  - í•œê¸€ í† í°í™” ì‹œ ì•½ 150~200í† í° ì˜ˆìƒ (ëª©í‘œ 50í† í°ì€ ì¶©ì¡±)
  - í•˜ì§€ë§Œ ë¬¸ì¥ ìˆ˜ëŠ” í™•ì¸ í•„ìš”

#### ë¬¸ì œì 

1. **ì „ì²´ ë¹„ë””ì˜¤ ì‹œê°„ ë¯¸ê³„ì‚°**: 3,600ì‹œê°„ ë‹¬ì„± ì—¬ë¶€ ë¶ˆëª…
2. **í† í° ìˆ˜ ë¯¸ì¸¡ì •**: GPT/Claude í† í°í™” ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚° í•„ìš”
3. **ë¬¸ì¥ ìˆ˜ ë¯¸ì¸¡ì •**: ì˜¨ì (.) ê¸°ì¤€ ë¬¸ì¥ ë¶„ë¦¬ í›„ ì¹´ìš´íŠ¸ í•„ìš”

#### ê°œì„  ë°©ì•ˆ

**Phase 1: ì „ì²´ ë¹„ë””ì˜¤ ì‹œê°„ ê³„ì‚° (ì¦‰ì‹œ)**
```python
# scripts/calculate_total_duration.py
import pandas as pd

df = pd.read_csv('all_train.csv')

# ë¹„ë””ì˜¤ë§Œ í•„í„°ë§
videos = df[df['media_type'] == 'video']

# ì´ ì‹œê°„ ê³„ì‚° (ì´ˆ â†’ ì‹œê°„)
total_seconds = videos['length'].sum()
total_hours = total_seconds / 3600

print(f"ì´ ë¹„ë””ì˜¤ ì‹œê°„: {total_hours:.2f}ì‹œê°„")
print(f"ëª©í‘œ: 3,600ì‹œê°„")

if total_hours >= 3600:
    print("âœ… ëª©í‘œ ë‹¬ì„±")
else:
    shortage = 3600 - total_hours
    print(f"âŒ ë¶€ì¡±: {shortage:.2f}ì‹œê°„ ({shortage/total_hours*100:.1f}%)")
```

**ì˜ˆìƒ ê²°ê³¼** (99,947ê°œ ë¹„ë””ì˜¤ Ã— 23.40ì´ˆ):
- ì´ ì‹œê°„: **ì•½ 650ì‹œê°„**
- **ë¶€ì¡±**: ì•½ 2,950ì‹œê°„ (82% ë¶€ì¡±)
- âŒ **ì‹¬ê°í•œ ë¯¸ë‹¬**

**Phase 2: ìº¡ì…˜ í† í° ë° ë¬¸ì¥ ìˆ˜ ì¸¡ì • (1ì¼)**
```python
# scripts/analyze_caption_requirements.py
import pandas as pd
import tiktoken  # OpenAI tokenizer

def count_sentences(text):
    """í•œê¸€ ë¬¸ì¥ ê°œìˆ˜ ì¹´ìš´íŠ¸"""
    # ì˜¨ì , ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¡œ ë¬¸ì¥ ë¶„ë¦¬
    sentences = text.replace('?', '.').replace('!', '.').split('.')
    sentences = [s.strip() for s in sentences if s.strip()]
    return len(sentences)

def analyze_captions(csv_path):
    df = pd.read_csv(csv_path)

    # OpenAI tiktoken ì¸ì½”ë”
    encoder = tiktoken.encoding_for_model("gpt-4")

    results = []

    for idx, row in df.iterrows():
        caption = str(row['caption'])

        # í† í° ìˆ˜
        tokens = encoder.encode(caption)
        token_count = len(tokens)

        # ë¬¸ì¥ ìˆ˜
        sentence_count = count_sentences(caption)

        results.append({
            'clip_id': row['clip_id'],
            'token_count': token_count,
            'sentence_count': sentence_count,
            'meets_token_req': token_count >= 50,
            'meets_sentence_req': sentence_count >= 5
        })

    results_df = pd.DataFrame(results)

    # í†µê³„
    print(f"í‰ê·  í† í° ìˆ˜: {results_df['token_count'].mean():.1f}")
    print(f"í‰ê·  ë¬¸ì¥ ìˆ˜: {results_df['sentence_count'].mean():.1f}")
    print(f"í† í° ìš”ê±´ ì¶©ì¡±: {results_df['meets_token_req'].sum() / len(results_df) * 100:.1f}%")
    print(f"ë¬¸ì¥ ìš”ê±´ ì¶©ì¡±: {results_df['meets_sentence_req'].sum() / len(results_df) * 100:.1f}%")

    # ë¯¸ë‹¬ì„± ìƒ˜í”Œ ì‹ë³„
    fails = results_df[~(results_df['meets_token_req'] & results_df['meets_sentence_req'])]
    fails.to_csv('caption_requirement_fails.csv', index=False)

    return results_df

# ì‹¤í–‰
results = analyze_captions('all_train.csv')
```

**Phase 3: ë¶€ì¡±í•œ ë¹„ë””ì˜¤ ì‹œê°„ í™•ë³´ ë°©ì•ˆ**

**Option 1: ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘** (ê¶Œì¥)
- MBC ì¶”ê°€ ë°©ì†¡ ì˜ìƒ 2,950ì‹œê°„ í™•ë³´
- í‰ê·  23ì´ˆ ê¸°ì¤€ ì•½ 454,000ê°œ í´ë¦½ í•„ìš”

**Option 2: ê¸°ì¡´ ì˜ìƒ ì¬ë¶„í• **
- ê¸´ ì›ë³¸ ì˜ìƒì„ ë” ë§ì€ í´ë¦½ìœ¼ë¡œ ë¶„í• 
- ì˜ˆ: 5ë¶„ ì˜ìƒ â†’ 15ê°œ í´ë¦½ (20ì´ˆì”©)

**Option 3: ëª©í‘œ ì¡°ì • í˜‘ì˜**
- RAPAì™€ í˜‘ì˜í•˜ì—¬ ëª©í‘œ ì‹œê°„ ì¡°ì • (3,600ì‹œê°„ â†’ ì‹¤ì œ ê°€ëŠ¥ ë²”ìœ„)

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œ 2~3ê°œì›”
**ì˜ˆìƒ ë¹„ìš©**: MBC ì¶”ê°€ ë¼ì´ì„ ìŠ¤ í˜‘ìƒ í•„ìš”

---

### 4. êµ¬ë¬¸ ì •í™•ì„± - âŒ Fë“±ê¸‰

#### ëª©í‘œ
- êµ¬ì¡° ì •í™•ì„±: 99.5% ì´ìƒ (JSON ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜)
- í˜•ì‹ ì •í™•ì„±: 99.5% ì´ìƒ (íƒ€ì„ì½”ë“œ, ë‚ ì§œ í˜•ì‹ ë“±)

#### í˜„ì¬ ìƒíƒœ
âŒ **ê²€ì¦ ë¯¸ì‹¤ì‹œ**

#### ë¬¸ì œì 

1. **JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì—†ìŒ**: ë¼ë²¨ë§ ë°ì´í„°ê°€ ê³µì‹ ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜í•˜ëŠ”ì§€ ë¯¸í™•ì¸
2. **í•„ìˆ˜ í•„ë“œ ê²€ì‚¬ ì—†ìŒ**: object_level, semantic_level, application_level ìº¡ì…˜ ì¡´ì¬ ì—¬ë¶€ ë¯¸í™•ì¸
3. **í˜•ì‹ ê²€ì¦ ì—†ìŒ**: íƒ€ì„ì½”ë“œ(00:00:00;00), ë‚ ì§œ, í•´ìƒë„ í˜•ì‹ ë¯¸ê²€ì¦

#### ê°œì„  ë°©ì•ˆ

**Phase 1: JSON ìŠ¤í‚¤ë§ˆ ì •ì˜ (1ì¼)**
```json
// schema/labeling_schema.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["file_id", "raw_data_info", "source_data_info", "labeling_data_info"],
  "properties": {
    "file_id": {
      "type": "string",
      "pattern": "^MBC[ê°€-í£]+_[ê°€-í£/]+_[0-9]+\\.mp4$"
    },
    "raw_data_info": {
      "type": "object",
      "required": ["raw_data_info", "source_media_info"]
    },
    "source_data_info": {
      "type": "object",
      "required": ["clip_id", "source_mbc", "broadcast_date", "ai_generated_info"]
    },
    "labeling_data_info": {
      "type": "object",
      "required": ["caption_info"],
      "properties": {
        "caption_info": {
          "type": "object",
          "required": ["object_level", "semantic_level", "application_level"],
          "properties": {
            "object_level": {
              "type": "array",
              "minItems": 1
            },
            "semantic_level": {
              "type": "array",
              "minItems": 1
            },
            "application_level": {
              "type": "array",
              "minItems": 1
            }
          }
        }
      }
    }
  }
}
```

**Phase 2: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (2ì¼)**
```python
# scripts/validate_json_schema.py
import json
import jsonschema
from pathlib import Path
from tqdm import tqdm

def validate_json_files(json_dir, schema_path):
    """ëª¨ë“  JSON íŒŒì¼ ìŠ¤í‚¤ë§ˆ ê²€ì¦"""

    # ìŠ¤í‚¤ë§ˆ ë¡œë“œ
    with open(schema_path) as f:
        schema = json.load(f)

    json_files = list(Path(json_dir).rglob('*.json'))

    valid = 0
    invalid = []

    for json_file in tqdm(json_files):
        with open(json_file) as f:
            data = json.load(f)

        try:
            jsonschema.validate(instance=data, schema=schema)
            valid += 1
        except jsonschema.exceptions.ValidationError as e:
            invalid.append({
                'file': str(json_file),
                'error': str(e.message),
                'path': list(e.path)
            })

    accuracy = (valid / len(json_files)) * 100

    print(f"êµ¬ì¡° ì •í™•ì„±: {accuracy:.2f}%")
    print(f"ìœ íš¨: {valid:,} / ë¬´íš¨: {len(invalid):,}")

    if accuracy >= 99.5:
        print("âœ… ëª©í‘œ ë‹¬ì„±")
    else:
        print(f"âŒ ëª©í‘œ ë¯¸ë‹¬ (ë¶€ì¡±: {99.5 - accuracy:.2f}%)")

    # ì˜¤ë¥˜ ë¦¬í¬íŠ¸ ì €ì¥
    if invalid:
        pd.DataFrame(invalid).to_csv('schema_validation_errors.csv', index=False)

    return accuracy

# ì‹¤í–‰
accuracy = validate_json_files('./preprocessed_data/jsons', './schema/labeling_schema.json')
```

**Phase 3: í˜•ì‹ ì •í™•ì„± ê²€ì¦ (1ì¼)**
```python
# scripts/validate_format_accuracy.py
import re
from datetime import datetime

def validate_timecode(tc):
    """íƒ€ì„ì½”ë“œ í˜•ì‹ ê²€ì¦: HH:MM:SS;FF"""
    pattern = r'^\d{2}:\d{2}:\d{2};\d{2}$'
    return bool(re.match(pattern, tc))

def validate_date(date_str):
    """ë‚ ì§œ í˜•ì‹ ê²€ì¦"""
    try:
        datetime.fromisoformat(date_str.replace('GMT+0900 (Korean Standard Time)', '').strip())
        return True
    except:
        return False

def validate_resolution(res_str):
    """í•´ìƒë„ í˜•ì‹ ê²€ì¦: 'width, height'"""
    pattern = r'^\d+,\s*\d+$'
    return bool(re.match(pattern, res_str))

def validate_formats(json_data):
    """ëª¨ë“  í˜•ì‹ ê²€ì¦"""
    errors = []

    # íƒ€ì„ì½”ë“œ ê²€ì¦
    for caption in json_data.get('labeling_data_info', {}).get('caption_info', {}).get('object_level', []):
        if not validate_timecode(caption.get('tc_in', '')):
            errors.append(f"Invalid tc_in: {caption.get('tc_in')}")
        if not validate_timecode(caption.get('tc_out', '')):
            errors.append(f"Invalid tc_out: {caption.get('tc_out')}")

    # ë‚ ì§œ ê²€ì¦
    broadcast_date = json_data.get('source_data_info', {}).get('broadcast_date', '')
    if not validate_date(broadcast_date):
        errors.append(f"Invalid broadcast_date: {broadcast_date}")

    # í•´ìƒë„ ê²€ì¦
    resolution = json_data.get('raw_data_info', {}).get('raw_data_info', {}).get('basic_info', {}).get('resolution', '')
    if not validate_resolution(resolution):
        errors.append(f"Invalid resolution: {resolution}")

    return len(errors) == 0, errors

# ì „ì²´ íŒŒì¼ ê²€ì¦ í›„ ì •í™•ë„ ê³„ì‚°
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 4ì¼
**ì˜ˆìƒ ê²°ê³¼**: êµ¬ì¡° ì •í™•ì„± 95~98%, í˜•ì‹ ì •í™•ì„± 96~99% ì˜ˆìƒ

---

### 5. ì˜ë¯¸ ì •í™•ì„± - âŒ Fë“±ê¸‰

#### ëª©í‘œ
- í‘œí˜„ ì ì ˆì„±: 90% ì´ìƒ
- ì˜ìƒ-ì„¤ëª…ë¬¸ ì¼ì¹˜ì„±: 90% ì´ìƒ

#### í˜„ì¬ ìƒíƒœ
âŒ **ê²€ì¦ ë¯¸ì‹¤ì‹œ**

#### ë¬¸ì œì 

1. **ìƒ˜í”Œë§ ê²€ì¦ ì—†ìŒ**: ì‹¤ì œ ìº¡ì…˜ í’ˆì§ˆ ìˆ˜ë™ ê²€ì‚¬ ì•ˆ í•¨
2. **ì¼ì¹˜ì„± í‰ê°€ ì—†ìŒ**: ìº¡ì…˜ê³¼ ì˜ìƒ ë‚´ìš©ì´ ë§¤ì¹­ë˜ëŠ”ì§€ ë¯¸í™•ì¸
3. **ê¸°ì¤€ ë¶ˆëª…í™•**: ë¬´ì—‡ì´ "ì ì ˆ"í•˜ê³  "ì¼ì¹˜"í•˜ëŠ”ì§€ ì •ì˜ í•„ìš”

#### ê°œì„  ë°©ì•ˆ

**Phase 1: í‰ê°€ ê¸°ì¤€ ì •ì˜ (1ì¼)**
```markdown
# ìº¡ì…˜ í’ˆì§ˆ í‰ê°€ ê¸°ì¤€

## í‘œí˜„ ì ì ˆì„±
1. ë¬¸ë²•: ì™„ê²°ëœ ë¬¸ì¥ êµ¬ì¡°
2. ë§ì¶¤ë²•: ì˜¤íƒ€ ì—†ìŒ
3. í‘œí˜„: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´
4. êµ¬ì²´ì„±: êµ¬ì²´ì  ëª…ì‚¬/ë™ì‚¬ ì‚¬ìš©
5. ì¼ê´€ì„±: ì‹œì œ/ì–´ì¡° ì¼ê´€

## ì˜ìƒ-ì„¤ëª…ë¬¸ ì¼ì¹˜ì„±
1. ê°ì²´ ì •í™•ë„: ì‹¤ì œ ë“±ì¥í•˜ëŠ” ê°ì²´ë§Œ ì–¸ê¸‰
2. í–‰ë™ ì •í™•ë„: ì‹¤ì œ ì¼ì–´ë‚˜ëŠ” í–‰ë™ë§Œ ì„œìˆ 
3. ì¥ë©´ ì •í™•ë„: ë°°ê²½/ì¥ì†Œ ì •í™• ë¬˜ì‚¬
4. ì‹œê°„ ìˆœì„œ: ì˜ìƒ íë¦„ëŒ€ë¡œ ì„œìˆ 
5. ì„¸ë¶€ ì •ë³´: ìƒ‰ìƒ, ìœ„ì¹˜ ë“± ì •í™•

ê° í•­ëª© 1~5ì , í‰ê·  3.5ì  ì´ìƒ â†’ ì ì ˆ/ì¼ì¹˜ë¡œ íŒì •
```

**Phase 2: ìƒ˜í”Œë§ ì „ëµ (1ì¼)**
```python
# scripts/sample_for_manual_review.py
import pandas as pd

def stratified_sampling(csv_path, n=1000):
    """ê³„ì¸µì  ìƒ˜í”Œë§"""
    df = pd.read_csv(csv_path)

    # ì¹´í…Œê³ ë¦¬ë³„ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ìƒ˜í”Œë§
    samples = df.groupby('category', group_keys=False).apply(
        lambda x: x.sample(n=int(len(x) / len(df) * n))
    )

    # ë¹„ë””ì˜¤ ê¸¸ì´ë³„ë¡œë„ ê· í˜•
    length_bins = [0, 15, 20, 25, 100]
    samples['length_bin'] = pd.cut(samples['length'], bins=length_bins)

    # ìµœì¢… ìƒ˜í”Œ ì €ì¥
    samples.to_csv('manual_review_samples.csv', index=False)

    print(f"ìƒ˜í”Œë§ ì™„ë£Œ: {len(samples)}ê°œ")
    print("\nì¹´í…Œê³ ë¦¬ ë¶„í¬:")
    print(samples['category'].value_counts())
    print("\nê¸¸ì´ ë¶„í¬:")
    print(samples['length_bin'].value_counts())

    return samples

# 1,000ê°œ ìƒ˜í”Œ ì¶”ì¶œ
samples = stratified_sampling('all_train.csv', n=1000)
```

**Phase 3: ê²€í†  ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶• (3ì¼)**
```python
# ê°„ë‹¨í•œ Flask ì›¹ ì¸í„°í˜ì´ìŠ¤
from flask import Flask, render_template, request
import pandas as pd

app = Flask(__name__)

samples = pd.read_csv('manual_review_samples.csv')
current_idx = 0

@app.route('/')
def review():
    global current_idx
    sample = samples.iloc[current_idx]

    return render_template('review.html',
        clip_id=sample['clip_id'],
        video_path=sample['file_path'],
        caption=sample['caption'],
        current=current_idx+1,
        total=len(samples)
    )

@app.route('/submit', methods=['POST'])
def submit():
    global current_idx

    # í‰ê°€ ì ìˆ˜ ì €ì¥
    scores = {
        'clip_id': samples.iloc[current_idx]['clip_id'],
        'expression_score': request.form.get('expression'),
        'alignment_score': request.form.get('alignment'),
        'comments': request.form.get('comments')
    }

    # CSVì— ì €ì¥
    with open('review_results.csv', 'a') as f:
        f.write(f"{scores['clip_id']},{scores['expression_score']},{scores['alignment_score']},{scores['comments']}\n")

    current_idx += 1
    return redirect('/')

# ì‹¤í–‰: python review_app.py
```

**Phase 4: í†µê³„ ê³„ì‚° (ì¦‰ì‹œ)**
```python
# scripts/calculate_semantic_accuracy.py
import pandas as pd

def calculate_accuracy(results_csv):
    df = pd.read_csv(results_csv)

    # 3.5ì  ì´ìƒì„ "ì ì ˆ/ì¼ì¹˜"ë¡œ íŒì •
    expression_pass = (df['expression_score'] >= 3.5).sum()
    alignment_pass = (df['alignment_score'] >= 3.5).sum()

    expression_rate = (expression_pass / len(df)) * 100
    alignment_rate = (alignment_pass / len(df)) * 100

    print(f"í‘œí˜„ ì ì ˆì„±: {expression_rate:.1f}%")
    print(f"ì˜ìƒ-ì„¤ëª…ë¬¸ ì¼ì¹˜ì„±: {alignment_rate:.1f}%")

    if expression_rate >= 90 and alignment_rate >= 90:
        print("âœ… ëª©í‘œ ë‹¬ì„±")
    else:
        print("âŒ ëª©í‘œ ë¯¸ë‹¬")

    return expression_rate, alignment_rate

# ì‹¤í–‰
exp_rate, align_rate = calculate_accuracy('review_results.csv')
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2ì£¼ (ê²€í† ì 2ëª… Ã— 1ì£¼ì¼)
**ì˜ˆìƒ ë¹„ìš©**: ê²€í†  ì¸ë ¥ ë¹„ìš© + ì‹œê°„

---

### 6. ìœ íš¨ì„± - âŒ Fë“±ê¸‰ (ìµœìš°ì„ !)

#### ëª©í‘œ
- **FVD (FrÃ©chet Video Distance): â‰¤ 1140**
- **CLIP Score: â‰¥ 0.3**

#### í˜„ì¬ ìƒíƒœ
âŒ **ì¸¡ì • ë¯¸ì‹¤ì‹œ**

**ì´ê²ƒì€ ê°€ì¥ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì…ë‹ˆë‹¤!**
ì‚¬ì—… ì„±ê³µ/ì‹¤íŒ¨ë¥¼ íŒê°€ë¦„í•˜ëŠ” í•µì‹¬ ì§€í‘œì…ë‹ˆë‹¤.

#### ë¬¸ì œì 

1. **CLIP Score ë¯¸ì¸¡ì •**: í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ì •ë ¬ë„ ë¶ˆëª…
2. **FVD ë¯¸ì¸¡ì •**: ë¹„ë””ì˜¤ í’ˆì§ˆ ê°ê´€ì  ì§€í‘œ ì—†ìŒ
3. **Reference Dataset ì—†ìŒ**: FVD ê³„ì‚°ì„ ìœ„í•œ ë¹„êµ ë°ì´í„°ì…‹ ë¶€ì¬

#### ê°œì„  ë°©ì•ˆ (ìµœìš°ì„  ì‘ì—…!)

**Phase 1: CLIP Score ì¸¡ì • (3ì¼, GPU í•„ìš”)**

```bash
# ì„¤ì¹˜
pip install git+https://github.com/openai/CLIP.git
pip install torch torchvision
```

```python
# scripts/calculate_clip_score_batch.py
import clip
import torch
import pandas as pd
import cv2
import numpy as np
from tqdm import tqdm
from PIL import Image

def calculate_clip_score(video_path, caption, model, preprocess, device):
    """ë‹¨ì¼ ë¹„ë””ì˜¤-ìº¡ì…˜ ìŒì˜ CLIP Score ê³„ì‚°"""

    # ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ìƒ˜í”Œë§ (ê· ë“±í•˜ê²Œ 8í”„ë ˆì„)
    cap = cv2.VideoCapture(video_path)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    frames = []
    frame_indices = np.linspace(0, frame_count-1, num=8, dtype=int)

    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_pil = Image.fromarray(frame_rgb)
            frames.append(preprocess(frame_pil))

    cap.release()

    if not frames:
        return 0.0

    # í”„ë ˆì„ í…ì„œ ì¤€ë¹„
    frames_tensor = torch.stack(frames).to(device)

    # í…ìŠ¤íŠ¸ í† í°í™”
    text_tokens = clip.tokenize([caption], truncate=True).to(device)

    # CLIP ì¸ì½”ë”©
    with torch.no_grad():
        frame_features = model.encode_image(frames_tensor)
        text_features = model.encode_text(text_tokens)

        # ì •ê·œí™”
        frame_features = frame_features / frame_features.norm(dim=-1, keepdim=True)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê° í”„ë ˆì„ê³¼ í…ìŠ¤íŠ¸)
        similarity = (frame_features @ text_features.T).squeeze()

        # í‰ê·  ìœ ì‚¬ë„
        clip_score = similarity.mean().item()

    return clip_score

def batch_calculate_clip(csv_path, sample_size=5000, model_name='ViT-B/32'):
    """ë°°ì¹˜ë¡œ CLIP Score ê³„ì‚°"""

    # CLIP ëª¨ë¸ ë¡œë“œ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load(model_name, device=device)

    # ë°ì´í„° ë¡œë“œ ë° ìƒ˜í”Œë§
    df = pd.read_csv(csv_path)
    videos_df = df[df['media_type'] == 'video'].sample(n=min(sample_size, len(df)))

    results = []

    for idx, row in tqdm(videos_df.iterrows(), total=len(videos_df)):
        try:
            score = calculate_clip_score(
                row['file_path'],
                row['caption'],
                model,
                preprocess,
                device
            )

            results.append({
                'clip_id': row['clip_id'],
                'clip_score': score
            })

        except Exception as e:
            print(f"Error processing {row['clip_id']}: {e}")
            continue

    # ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame(results)
    results_df.to_csv('clip_scores.csv', index=False)

    # í†µê³„
    mean_score = results_df['clip_score'].mean()
    median_score = results_df['clip_score'].median()
    pass_rate = (results_df['clip_score'] >= 0.3).sum() / len(results_df) * 100

    print(f"\n=== CLIP Score ê²°ê³¼ ===")
    print(f"ìƒ˜í”Œ ìˆ˜: {len(results_df):,}")
    print(f"í‰ê·  CLIP Score: {mean_score:.4f}")
    print(f"ì¤‘ì•™ê°’: {median_score:.4f}")
    print(f"0.3 ì´ìƒ ë¹„ìœ¨: {pass_rate:.1f}%")

    if mean_score >= 0.3:
        print("âœ… ëª©í‘œ ë‹¬ì„±")
    else:
        shortage = 0.3 - mean_score
        print(f"âŒ ëª©í‘œ ë¯¸ë‹¬ (ë¶€ì¡±: {shortage:.4f})")

    return results_df, mean_score

# ì‹¤í–‰
results, avg_score = batch_calculate_clip('all_train.csv', sample_size=5000)
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3ì¼ (V100 GPU Ã— 2)
**ì˜ˆìƒ ê²°ê³¼**: CLIP Score 0.25~0.35 ì˜ˆìƒ (ê²½ê³„ì„ )

**Phase 2: FVD ì¸¡ì • (5ì¼, GPU í•„ìš”)**

```bash
# ì„¤ì¹˜
pip install tensorflow-gpu tensorflow-gan
```

```python
# scripts/calculate_fvd_batch.py
import tensorflow as tf
import tensorflow_gan as tfgan
import numpy as np
from tqdm import tqdm

def load_videos(video_paths, num_frames=16):
    """ë¹„ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    videos = []

    for path in video_paths:
        cap = cv2.VideoCapture(path)
        frames = []

        # ê· ë“± ìƒ˜í”Œë§
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        indices = np.linspace(0, frame_count-1, num=num_frames, dtype=int)

        for idx in indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if ret:
                # ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”
                frame = cv2.resize(frame, (224, 224))
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames.append(frame)

        cap.release()

        if len(frames) == num_frames:
            videos.append(np.array(frames))

    return np.array(videos)

def calculate_fvd(real_videos, generated_videos):
    """FVD ê³„ì‚°"""

    # I3D ëª¨ë¸ ë¡œë“œ (ImageNet + Kinetics ì‚¬ì „í•™ìŠµ)
    i3d_model = tfgan.eval.get_inception_model()

    # íŠ¹ì§• ì¶”ì¶œ
    print("Extracting features from real videos...")
    real_features = i3d_model(real_videos)

    print("Extracting features from generated/dataset videos...")
    gen_features = i3d_model(generated_videos)

    # FVD ê³„ì‚°
    fvd_score = tfgan.eval.frechet_inception_distance(
        real_features,
        gen_features
    )

    return fvd_score

def batch_calculate_fvd(dataset_csv, reference_dir, sample_size=2000):
    """ë°°ì¹˜ë¡œ FVD ê³„ì‚°"""

    # ë°ì´í„°ì…‹ ë¹„ë””ì˜¤
    df = pd.read_csv(dataset_csv)
    dataset_videos = df[df['media_type'] == 'video'].sample(n=sample_size)
    dataset_paths = dataset_videos['file_path'].tolist()

    # Reference ë¹„ë””ì˜¤ (ê³ í’ˆì§ˆ ì‹¤ì‚¬ ë¹„ë””ì˜¤)
    # Kinetics-700, WebVid, ë˜ëŠ” ìì²´ ê³ í’ˆì§ˆ ì…‹
    reference_paths = list(Path(reference_dir).glob('*.mp4'))[:sample_size]

    print(f"Loading {len(dataset_paths)} dataset videos...")
    dataset_vids = load_videos(dataset_paths)

    print(f"Loading {len(reference_paths)} reference videos...")
    reference_vids = load_videos([str(p) for p in reference_paths])

    print("Calculating FVD...")
    fvd = calculate_fvd(reference_vids, dataset_vids)

    print(f"\n=== FVD ê²°ê³¼ ===")
    print(f"FVD Score: {fvd:.2f}")
    print(f"ëª©í‘œ: â‰¤ 1140")

    if fvd <= 1140:
        print("âœ… ëª©í‘œ ë‹¬ì„±")
    else:
        excess = fvd - 1140
        print(f"âŒ ëª©í‘œ ì´ˆê³¼ (+{excess:.2f})")

    return fvd

# Reference ë°ì´í„°ì…‹ ì¤€ë¹„ í•„ìš”!
# Option 1: Kinetics-700 ë‹¤ìš´ë¡œë“œ
# Option 2: WebVid-10M ìƒ˜í”Œ
# Option 3: ìì²´ ê³ í’ˆì§ˆ MBC ì˜ìƒ ì…‹

fvd_score = batch_calculate_fvd(
    'all_train.csv',
    '/path/to/reference_videos',
    sample_size=2000
)
```

**ì¤‘ìš”: Reference Dataset ì¤€ë¹„**
```bash
# Option 1: Kinetics-700 ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)
# ê³ í’ˆì§ˆ ì•¡ì…˜ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹
git clone https://github.com/cvdfoundation/kinetics-dataset
python download.py --classes 50 --num_workers 8

# Option 2: ìì²´ Reference êµ¬ì¶•
# MBCì˜ ê³ í’ˆì§ˆ HD ë°©ì†¡ ì˜ìƒ ì¤‘ ìš°ìˆ˜í•œ ê²ƒ 2,000ê°œ ì„ ë³„
# - ì†ìƒ ì—†ìŒ
# - 1080p ì´ìƒ
# - ì¡°ëª…/ìƒ‰ê° ìš°ìˆ˜
# - ì¹´ë©”ë¼ ì›Œí¬ ì•ˆì •ì 
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 1ì£¼ì¼ (Reference ì¤€ë¹„ 3ì¼ + ê³„ì‚° 2ì¼)
**ì˜ˆìƒ ë¹„ìš©**: V100 GPU 80ì‹œê°„ ($400~$800)

**ì˜ˆìƒ ê²°ê³¼**:
- CLIP Score: 0.25~0.30 (ê²½ê³„ì„ , ìº¡ì…˜ ê°œì„  í•„ìš”í•  ìˆ˜ ìˆìŒ)
- FVD: 800~1500 (ë¶ˆí™•ì‹¤, Reference í’ˆì§ˆì— ë”°ë¼ ë³€ë™)

---

## ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ë¡œë“œë§µ

### ğŸ”´ Critical (ì¦‰ì‹œ ì‹¤í–‰, 1ì£¼ì¼)

1. **CLIP Score ì¸¡ì •** (3ì¼)
   - 5,000ê°œ ìƒ˜í”Œ ì¸¡ì •
   - GPU: V100 Ã— 2, 48ì‹œê°„
   - ì˜ˆì‚°: $200~$400

2. **FVD ì¸¡ì •** (4ì¼)
   - Reference dataset ì¤€ë¹„
   - 2,000ê°œ ìƒ˜í”Œ ì¸¡ì •
   - GPU: V100 Ã— 2, 32ì‹œê°„
   - ì˜ˆì‚°: $300~$600

**ì´ ë‘ ë©”íŠ¸ë¦­ì´ ëª©í‘œ ë¯¸ë‹¬ì´ë©´ ì‚¬ì—… ìì²´ê°€ ìœ„í—˜í•©ë‹ˆë‹¤!**

### ğŸŸ  High Priority (2ì£¼ ì´ë‚´)

3. **ì¥í¸ ë¹„ë””ì˜¤ ì²˜ë¦¬** (3ì¼)
   - 25ì´ˆ ì´ìƒ 14.9% â†’ 2% ë¯¸ë§Œìœ¼ë¡œ ê°ì¶•
   - íŠ¸ë¦¬ë° ë˜ëŠ” ì œê±°

4. **ìº¡ì…˜ í† í°/ë¬¸ì¥ ìˆ˜ ê²€ì¦** (2ì¼)
   - 50í† í°, 5ë¬¸ì¥ ìš”ê±´ í™•ì¸
   - ë¯¸ë‹¬ ìƒ˜í”Œ ë³´ì™„

5. **íŒŒì¼ ìœ íš¨ì„± ê²€ì¦** (3ì¼)
   - ì „ìˆ˜ ê²€ì‚¬: íŒŒì¼ ì¡´ì¬, ì†ìƒ ì—¬ë¶€
   - ëª©í‘œ: 99% ì´ìƒ

### ğŸŸ¡ Medium Priority (1ê°œì›” ì´ë‚´)

6. **JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦** (4ì¼)
   - ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ì „ìˆ˜ ê²€ì‚¬
   - ëª©í‘œ: 99.5% ì´ìƒ

7. **ì¹´í…Œê³ ë¦¬ ë¦¬ë°¸ëŸ°ì‹±** (1ì£¼)
   - ì˜¤ë²„/ì–¸ë” ìƒ˜í”Œë§
   - ìµœëŒ€ í¸ì°¨ 10%p ì´ë‚´

8. **ë¹„ë””ì˜¤ ì‹œê°„ í™•ë³´** (í˜‘ì˜)
   - í˜„ì¬: ~650ì‹œê°„
   - ëª©í‘œ: 3,600ì‹œê°„
   - ë¶€ì¡±: ~2,950ì‹œê°„

### ğŸŸ¢ Low Priority (2ê°œì›” ì´ë‚´)

9. **ì˜ë¯¸ ì •í™•ì„± ìˆ˜ë™ ê²€ì¦** (2ì£¼)
   - 1,000ê°œ ìƒ˜í”Œ ìˆ˜ë™ ê²€í† 
   - ê²€í†  ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•

10. **ë©”íƒ€ë°ì´í„° ì •í™•ì„± ê²€ì¦** (1ì£¼)
    - ì‹¤ì œ íŒŒì¼ê³¼ ë¹„êµ
    - ëª©í‘œ: 99% ì´ìƒ

---

## ğŸ“Š ì˜ˆìƒ ìµœì¢… ê²°ê³¼

### ëª¨ë“  ê°œì„  ì‘ì—… ì™„ë£Œ ì‹œ

| í’ˆì§ˆ íŠ¹ì„± | í˜„ì¬ | ê°œì„  í›„ | ëª©í‘œ | ë‹¬ì„± |
|----------|------|---------|------|------|
| í˜•ì‹ì„± | 0% | **99.2%** | 99% | âœ… |
| ë‹¤ì–‘ì„±(í†µê³„) | 60% | **85%** | ë¶„í¬ í™•ì¸ | âœ… |
| ë‹¤ì–‘ì„±(ìš”ê±´) | 50% | **70%** | ìµœì†Œê°’ | âš ï¸ |
| êµ¬ë¬¸ ì •í™•ì„± | 0% | **99.3%** | 99.5% | âš ï¸ |
| ì˜ë¯¸ ì •í™•ì„± | 0% | **91%** | 90% | âœ… |
| ìœ íš¨ì„± | 0% | **CLIP: 0.28, FVD: 1250** | CLIP â‰¥0.3, FVD â‰¤1140 | âŒ |

### ì¢…í•© ì ìˆ˜: **75/100ì  (Cë“±ê¸‰)**

**íŒì •**: âš ï¸ **ì¡°ê±´ë¶€ í•©ê²© (ê°œì„  í•„ìš”)**

### í•µì‹¬ ë¦¬ìŠ¤í¬

1. **ë¹„ë””ì˜¤ ì‹œê°„ ë¶€ì¡±**: 650ì‹œê°„ vs ëª©í‘œ 3,600ì‹œê°„ (18% ë‹¬ì„±)
2. **CLIP Score ë¶ˆí™•ì‹¤**: ì‹¤ì¸¡ ì „ê¹Œì§€ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ ë¶ˆëª…
3. **FVD ë¶ˆí™•ì‹¤**: Reference dataset í’ˆì§ˆì— ë”°ë¼ ë³€ë™

---

## ğŸ’° ì´ ì†Œìš” ì˜ˆì‚° ë° ì‹œê°„

### ì˜ˆì‚°
- GPU ë¹„ìš©: $800~$1,500
- ì¸ë ¥ ë¹„ìš© (ê²€í† ì): $2,000~$4,000
- ìŠ¤í† ë¦¬ì§€: $50
- **ì´ ì˜ˆì‚°: $3,000~$6,000**

### ì‹œê°„
- Critical ì‘ì—…: 1ì£¼
- High Priority: 2ì£¼
- Medium Priority: 4ì£¼
- Low Priority: 8ì£¼
- **ì´ ì†Œìš” ì‹œê°„: 2~3ê°œì›”**

### ì¸ë ¥
- ML ì—”ì§€ë‹ˆì–´: 1ëª… (í’€íƒ€ì„)
- ë°ì´í„° ê²€ì¦ì: 2ëª… (íŒŒíŠ¸íƒ€ì„)
- GPU ì—”ì§€ë‹ˆì–´: 1ëª… (íŒŒíŠ¸íƒ€ì„)

---

## ğŸš¨ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” ì‚¬í•­

### ì˜¤ëŠ˜ ë°”ë¡œ ì‹œì‘
1. âœ… CLIP Score ì¸¡ì • í™˜ê²½ êµ¬ì¶•
2. âœ… Reference dataset í™•ë³´ ì‹œì‘
3. âœ… GPU ë¦¬ì†ŒìŠ¤ í™•ë³´ (V100 Ã— 2)

### ì´ë²ˆ ì£¼ ë‚´
4. âœ… CLIP Score ì „ìˆ˜ ì¸¡ì •
5. âœ… FVD ê³„ì‚° ì™„ë£Œ
6. âœ… ì¥í¸ ë¹„ë””ì˜¤ íŠ¸ë¦¬ë° ì‹œì‘

### 2ì£¼ ë‚´
7. âœ… íŒŒì¼ ìœ íš¨ì„± ì „ìˆ˜ ê²€ì‚¬
8. âœ… ìº¡ì…˜ ìš”ê±´ ê²€ì¦
9. âœ… ê°œì„  ê³„íš RAPA ë³´ê³ 

---

**ê²°ë¡ **: í˜„ì¬ ë°ì´í„°ì…‹ì€ ê³µì‹ í’ˆì§ˆì§€í‘œ ê¸°ì¤€ì— í¬ê²Œ ë¯¸ë‹¬í•©ë‹ˆë‹¤. íŠ¹íˆ **ìœ íš¨ì„±(CLIP/FVD)**ê³¼ **ë‹¤ì–‘ì„±(ìš”ê±´)** í•­ëª©ì´ ì‹¬ê°í•˜ë©°, ì¦‰ê°ì ì¸ ì¸¡ì •ê³¼ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. 2~3ê°œì›”ì˜ ì§‘ì¤‘ì ì¸ í’ˆì§ˆ ê°œì„  ì‘ì—…ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
