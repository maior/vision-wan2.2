#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
RAPA 2025 ê¸°ì¤€ + COT êµ¬ì¡° ê²€ì¦
"""

import csv
import json
import os
from pathlib import Path
from collections import defaultdict

# ê²½ë¡œ ì„¤ì •
CSV_PATH = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data/all_train_cot.csv'
OUTPUT_REPORT = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data/quality_validation_report.json'

print("=" * 70)
print("ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦")
print("=" * 70)
print(f"ì…ë ¥ CSV: {CSV_PATH}")
print(f"ì¶œë ¥ ë¦¬í¬íŠ¸: {OUTPUT_REPORT}")
print("=" * 70)

# ê²€ì¦ ê¸°ì¤€
RAPA_MIN_TOKENS = 50
RAPA_MIN_APPLICATIONS = 5

# í†µê³„
validation_stats = {
    'total_samples': 0,
    'media_type': {'video': 0, 'image': 0},

    # COT êµ¬ì¡°
    'cot_structure': {
        'has_cot': 0,
        'no_cot': 0,
        'has_object_level': 0,
        'has_semantic_level': 0,
        'has_application_level': 0,
        'complete_cot': 0  # 3ê°œ ë ˆë²¨ ëª¨ë‘ ìˆìŒ
    },

    # í† í° ë¶„í¬
    'token_distribution': {
        '0': 0,           # í† í° ì—†ìŒ
        '1-25': 0,        # ë§¤ìš° ë¶€ì¡±
        '26-49': 0,       # ë¶€ì¡±
        '50-99': 0,       # ê¸°ì¤€ ì¶©ì¡±
        '100-199': 0,     # ìš°ìˆ˜
        '200+': 0         # ë§¤ìš° ìš°ìˆ˜
    },

    # RAPA 2025 ê¸°ì¤€
    'rapa_criteria': {
        'token_pass': 0,           # 50+ í† í°
        'token_fail': 0,
        'application_pass': 0,     # 5+ í™œìš©ë¶„ì•¼
        'application_fail': 0,
        'both_pass': 0,            # ë‘˜ ë‹¤ í†µê³¼
        'both_fail': 0
    },

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    'by_category': defaultdict(lambda: {
        'count': 0,
        'avg_tokens': 0,
        'quality_pass': 0
    }),

    # í’ˆì§ˆ ì´ìŠˆ
    'issues': {
        'empty_caption': 0,
        'no_category': 0,
        'no_keyword': 0,
        'file_not_exist': 0
    },

    # ìƒ˜í”Œ ì˜ˆì‹œ
    'samples': {
        'excellent': [],  # 200+ í† í°
        'good': [],       # 50-199 í† í°
        'poor': [],       # < 50 í† í°
        'no_cot': []      # COT ì—†ìŒ
    }
}

def classify_token_range(tokens):
    """í† í° ìˆ˜ë¥¼ ë²”ìœ„ë¡œ ë¶„ë¥˜"""
    if tokens == 0:
        return '0'
    elif tokens <= 25:
        return '1-25'
    elif tokens <= 49:
        return '26-49'
    elif tokens <= 99:
        return '50-99'
    elif tokens <= 199:
        return '100-199'
    else:
        return '200+'

def validate_row(row):
    """ê° row ê²€ì¦"""
    issues = []

    # í•„ìˆ˜ í•„ë“œ ì²´í¬
    if not row.get('caption_full', '').strip():
        issues.append('empty_caption')

    if not row.get('category', '').strip():
        issues.append('no_category')

    if not row.get('keyword', '').strip():
        issues.append('no_keyword')

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    file_path = row.get('file_path', '')
    if file_path and not os.path.exists(file_path):
        issues.append('file_not_exist')

    return issues

# CSV ì½ê¸° ë° ê²€ì¦
print("\nê²€ì¦ ì‹œì‘...\n")

samples_collected = {'excellent': 0, 'good': 0, 'poor': 0, 'no_cot': 0}
MAX_SAMPLES_PER_TYPE = 5

with open(CSV_PATH, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)

    for row in reader:
        validation_stats['total_samples'] += 1

        # ë¯¸ë””ì–´ íƒ€ì…
        media_type = row.get('media_type', 'unknown')
        validation_stats['media_type'][media_type] = validation_stats['media_type'].get(media_type, 0) + 1

        # COT êµ¬ì¡° ë¶„ì„
        has_cot = row.get('has_cot', 'False').lower() == 'true'
        tokens_object = int(row.get('tokens_object', 0))
        tokens_semantic = int(row.get('tokens_semantic', 0))
        tokens_application = int(row.get('tokens_application', 0))
        tokens_total = int(row.get('tokens_total', 0))
        num_applications = int(row.get('num_application_areas', 0))

        if has_cot:
            validation_stats['cot_structure']['has_cot'] += 1
        else:
            validation_stats['cot_structure']['no_cot'] += 1

        if tokens_object > 0:
            validation_stats['cot_structure']['has_object_level'] += 1
        if tokens_semantic > 0:
            validation_stats['cot_structure']['has_semantic_level'] += 1
        if tokens_application > 0:
            validation_stats['cot_structure']['has_application_level'] += 1

        if tokens_object > 0 and tokens_semantic > 0 and tokens_application > 0:
            validation_stats['cot_structure']['complete_cot'] += 1

        # í† í° ë¶„í¬
        token_range = classify_token_range(tokens_total)
        validation_stats['token_distribution'][token_range] += 1

        # RAPA ê¸°ì¤€ ê²€ì¦
        token_pass = tokens_total >= RAPA_MIN_TOKENS
        application_pass = num_applications >= RAPA_MIN_APPLICATIONS

        if token_pass:
            validation_stats['rapa_criteria']['token_pass'] += 1
        else:
            validation_stats['rapa_criteria']['token_fail'] += 1

        if application_pass:
            validation_stats['rapa_criteria']['application_pass'] += 1
        else:
            validation_stats['rapa_criteria']['application_fail'] += 1

        if token_pass and application_pass:
            validation_stats['rapa_criteria']['both_pass'] += 1
        else:
            validation_stats['rapa_criteria']['both_fail'] += 1

        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category = row.get('category', 'ë¯¸ë¶„ë¥˜')
        cat_stats = validation_stats['by_category'][category]
        cat_stats['count'] += 1
        cat_stats['avg_tokens'] += tokens_total
        if token_pass and application_pass:
            cat_stats['quality_pass'] += 1

        # ì´ìŠˆ ê²€ì¦
        issues = validate_row(row)
        for issue in issues:
            validation_stats['issues'][issue] += 1

        # ìƒ˜í”Œ ìˆ˜ì§‘ (ê° íƒ€ì…ë‹¹ ìµœëŒ€ 5ê°œ)
        sample_data = {
            'clip_id': row['clip_id'],
            'media_type': media_type,
            'tokens_total': tokens_total,
            'tokens_object': tokens_object,
            'tokens_semantic': tokens_semantic,
            'tokens_application': tokens_application,
            'num_applications': num_applications,
            'category': category,
            'caption_preview': row.get('caption_full', '')[:150] + '...'
        }

        if tokens_total >= 200 and samples_collected['excellent'] < MAX_SAMPLES_PER_TYPE:
            validation_stats['samples']['excellent'].append(sample_data)
            samples_collected['excellent'] += 1
        elif 50 <= tokens_total < 200 and samples_collected['good'] < MAX_SAMPLES_PER_TYPE:
            validation_stats['samples']['good'].append(sample_data)
            samples_collected['good'] += 1
        elif 0 < tokens_total < 50 and samples_collected['poor'] < MAX_SAMPLES_PER_TYPE:
            validation_stats['samples']['poor'].append(sample_data)
            samples_collected['poor'] += 1
        elif not has_cot and samples_collected['no_cot'] < MAX_SAMPLES_PER_TYPE:
            validation_stats['samples']['no_cot'].append(sample_data)
            samples_collected['no_cot'] += 1

        # ì§„í–‰ ìƒí™©
        if validation_stats['total_samples'] % 10000 == 0:
            print(f"[ì§„í–‰] {validation_stats['total_samples']:,} ê²€ì¦ ì™„ë£Œ")

# ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ê³„ì‚°
for category, stats in validation_stats['by_category'].items():
    if stats['count'] > 0:
        stats['avg_tokens'] = stats['avg_tokens'] / stats['count']

# ë°±ë¶„ìœ¨ ì¶”ê°€ ê³„ì‚°
total = validation_stats['total_samples']
if total > 0:
    validation_stats['percentages'] = {
        'cot_coverage': validation_stats['cot_structure']['has_cot'] / total * 100,
        'complete_cot_rate': validation_stats['cot_structure']['complete_cot'] / total * 100,
        'rapa_pass_rate': validation_stats['rapa_criteria']['both_pass'] / total * 100,
        'token_pass_rate': validation_stats['rapa_criteria']['token_pass'] / total * 100,
        'application_pass_rate': validation_stats['rapa_criteria']['application_pass'] / total * 100
    }

# JSONìœ¼ë¡œ ì €ì¥
with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
    json.dump(validation_stats, f, ensure_ascii=False, indent=2)

# ì½˜ì†” ì¶œë ¥
print("\n" + "=" * 70)
print("ê²€ì¦ ì™„ë£Œ!")
print("=" * 70)
print(f"\nğŸ“Š ì „ì²´ í†µê³„")
print(f"  ì´ ìƒ˜í”Œ: {total:,}ê°œ")
print(f"  ë¹„ë””ì˜¤: {validation_stats['media_type'].get('video', 0):,}ê°œ")
print(f"  ì´ë¯¸ì§€: {validation_stats['media_type'].get('image', 0):,}ê°œ")

print(f"\nğŸ“ COT êµ¬ì¡°")
print(f"  COT ìˆìŒ: {validation_stats['cot_structure']['has_cot']:,}ê°œ "
      f"({validation_stats['percentages']['cot_coverage']:.1f}%)")
print(f"  COT ì—†ìŒ: {validation_stats['cot_structure']['no_cot']:,}ê°œ")
print(f"  ì™„ì „í•œ COT (3ë ˆë²¨): {validation_stats['cot_structure']['complete_cot']:,}ê°œ "
      f"({validation_stats['percentages']['complete_cot_rate']:.1f}%)")

print(f"\nğŸ¯ RAPA 2025 ê¸°ì¤€")
print(f"  í† í° 50+ í†µê³¼: {validation_stats['rapa_criteria']['token_pass']:,}ê°œ "
      f"({validation_stats['percentages']['token_pass_rate']:.1f}%)")
print(f"  í™œìš©ë¶„ì•¼ 5+ í†µê³¼: {validation_stats['rapa_criteria']['application_pass']:,}ê°œ "
      f"({validation_stats['percentages']['application_pass_rate']:.1f}%)")
print(f"  ì „ì²´ í†µê³¼: {validation_stats['rapa_criteria']['both_pass']:,}ê°œ "
      f"({validation_stats['percentages']['rapa_pass_rate']:.1f}%)")
print(f"  ì „ì²´ ë¯¸í†µê³¼: {validation_stats['rapa_criteria']['both_fail']:,}ê°œ")

print(f"\nğŸ“ˆ í† í° ë¶„í¬")
for range_name, count in sorted(validation_stats['token_distribution'].items()):
    pct = count / total * 100 if total > 0 else 0
    print(f"  {range_name:>8} í† í°: {count:>7,}ê°œ ({pct:>5.1f}%)")

print(f"\nâš ï¸  í’ˆì§ˆ ì´ìŠˆ")
for issue, count in validation_stats['issues'].items():
    pct = count / total * 100 if total > 0 else 0
    print(f"  {issue:20}: {count:>7,}ê°œ ({pct:>5.1f}%)")

print(f"\nğŸ’¾ ìƒì„¸ ë¦¬í¬íŠ¸: {OUTPUT_REPORT}")
print("=" * 70)
