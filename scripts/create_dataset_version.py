#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ ë²„ì „ ì •ë³´ ìƒì„±
ì¬í˜„ì„± ë° ì¶”ì ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° ì €ì¥
"""

import json
import hashlib
import os
import csv
from datetime import datetime
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
CSV_PATH = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data/all_train_cot.csv'
VALIDATION_REPORT = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data/quality_validation_report.json'
VERSION_FILE = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data/dataset_version.json'
PREPROCESSED_DIR = '/home/maiordba/projects/vision/Wan2.2/preprocessed_data'

print("=" * 70)
print("ë°ì´í„°ì…‹ ë²„ì „ ì •ë³´ ìƒì„±")
print("=" * 70)

def compute_file_hash(file_path, chunk_size=8192):
    """íŒŒì¼ì˜ MD5 í•´ì‹œ ê³„ì‚°"""
    md5 = hashlib.md5()
    try:
        with open(file_path, 'rb') as f:
            while chunk := f.read(chunk_size):
                md5.update(chunk)
        return md5.hexdigest()
    except Exception as e:
        return f"ERROR: {e}"

def get_file_stats(file_path):
    """íŒŒì¼ í†µê³„ ì •ë³´"""
    try:
        stat = os.stat(file_path)
        return {
            'size_bytes': stat.st_size,
            'size_mb': round(stat.st_size / (1024 * 1024), 2),
            'modified': datetime.fromtimestamp(stat.st_mtime).isoformat()
        }
    except:
        return None

def count_csv_rows(csv_path):
    """CSV í–‰ ìˆ˜ ì¹´ìš´íŠ¸"""
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            return sum(1 for _ in f) - 1  # í—¤ë” ì œì™¸
    except:
        return 0

def get_git_info():
    """Git ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    import subprocess
    try:
        commit = subprocess.check_output(
            ['git', 'rev-parse', 'HEAD'],
            cwd='/home/maiordba/projects/vision/Wan2.2',
            stderr=subprocess.DEVNULL
        ).decode().strip()

        branch = subprocess.check_output(
            ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],
            cwd='/home/maiordba/projects/vision/Wan2.2',
            stderr=subprocess.DEVNULL
        ).decode().strip()

        return {
            'commit': commit,
            'branch': branch
        }
    except:
        return {'commit': 'N/A', 'branch': 'N/A'}

print("\níŒŒì¼ í•´ì‹œ ê³„ì‚° ì¤‘...")
csv_hash = compute_file_hash(CSV_PATH)
print(f"  CSV í•´ì‹œ: {csv_hash}")

print("\níŒŒì¼ í†µê³„ ìˆ˜ì§‘ ì¤‘...")
csv_stats = get_file_stats(CSV_PATH)

print("\ní’ˆì§ˆ ë¦¬í¬íŠ¸ ë¡œë“œ ì¤‘...")
validation_data = None
if os.path.exists(VALIDATION_REPORT):
    with open(VALIDATION_REPORT, 'r', encoding='utf-8') as f:
        validation_data = json.load(f)

print("\nGit ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
git_info = get_git_info()

# ì „ì²˜ë¦¬ëœ íŒŒì¼ í†µê³„
print("\nì „ì²˜ë¦¬ íŒŒì¼ í†µê³„ ìˆ˜ì§‘ ì¤‘...")
video_dir = Path(PREPROCESSED_DIR) / 'converted_720p'
image_dir = Path(PREPROCESSED_DIR) / 'images_1280x720'

video_files = list(video_dir.rglob('*.mp4')) if video_dir.exists() else []
image_files = list(image_dir.rglob('*.png')) if image_dir.exists() else []

preprocessed_stats = {
    'video': {
        'count': len(video_files),
        'total_size_gb': sum(f.stat().st_size for f in video_files) / (1024**3) if video_files else 0
    },
    'image': {
        'count': len(image_files),
        'total_size_gb': sum(f.stat().st_size for f in image_files) / (1024**3) if image_files else 0
    }
}

# ë²„ì „ ì •ë³´ ìƒì„±
version_info = {
    'version': 'v1.0.0',
    'created_at': datetime.now().isoformat(),
    'dataset_name': 'MBC_Wan2.2_LoRA_Training',

    # ë°ì´í„°ì…‹ íŒŒì¼
    'files': {
        'main_csv': {
            'path': CSV_PATH,
            'hash': csv_hash,
            'rows': count_csv_rows(CSV_PATH),
            'stats': csv_stats
        }
    },

    # ì „ì²˜ë¦¬ í†µê³„
    'preprocessing': {
        'video_dir': str(video_dir),
        'image_dir': str(image_dir),
        'video_files': preprocessed_stats['video']['count'],
        'image_files': preprocessed_stats['image']['count'],
        'total_size_gb': preprocessed_stats['video']['total_size_gb'] + preprocessed_stats['image']['total_size_gb'],
        'resolution': '1280x720',
        'completed_at': datetime.now().isoformat()
    },

    # í’ˆì§ˆ ì§€í‘œ
    'quality_metrics': {},

    # Git ì •ë³´
    'git': git_info,

    # í™˜ê²½ ì •ë³´
    'environment': {
        'python_version': '3.x',
        'server': 'maiordba@server',
        'gpu': 'V100 32GB x 2'
    },

    # í•™ìŠµ ì¤€ë¹„ ìƒíƒœ
    'training_ready': False,

    # ë³€ê²½ ì´ë ¥
    'changelog': [
        {
            'version': 'v1.0.0',
            'date': datetime.now().isoformat(),
            'changes': [
                'COT êµ¬ì¡°ë¥¼ í¬í•¨í•œ CSV ìƒì„±',
                '170,180ê°œ ìƒ˜í”Œ (ë¹„ë””ì˜¤ 80,106 + ì´ë¯¸ì§€ 90,074)',
                '1280x720 í•´ìƒë„ë¡œ ì „ì²˜ë¦¬ ì™„ë£Œ',
                'RAPA 2025 í’ˆì§ˆ ê¸°ì¤€ ê²€ì¦ ì¶”ê°€'
            ]
        }
    ]
}

# ê²€ì¦ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í’ˆì§ˆ ì§€í‘œ ì¶”ê°€
if validation_data:
    version_info['quality_metrics'] = {
        'total_samples': validation_data.get('total_samples', 0),
        'cot_coverage': validation_data.get('percentages', {}).get('cot_coverage', 0),
        'complete_cot_rate': validation_data.get('percentages', {}).get('complete_cot_rate', 0),
        'rapa_pass_rate': validation_data.get('percentages', {}).get('rapa_pass_rate', 0),
        'token_pass_rate': validation_data.get('percentages', {}).get('token_pass_rate', 0),
        'application_pass_rate': validation_data.get('percentages', {}).get('application_pass_rate', 0),
        'avg_tokens': sum(
            validation_data.get('token_distribution', {}).values()
        ) / max(validation_data.get('total_samples', 1), 1)
    }

    # í•™ìŠµ ì¤€ë¹„ ìƒíƒœ íŒë‹¨
    version_info['training_ready'] = (
        validation_data.get('total_samples', 0) > 100000 and
        preprocessed_stats['video']['count'] > 70000 and
        preprocessed_stats['image']['count'] > 80000
    )

# JSON ì €ì¥
with open(VERSION_FILE, 'w', encoding='utf-8') as f:
    json.dump(version_info, f, ensure_ascii=False, indent=2)

# ì½˜ì†” ì¶œë ¥
print("\n" + "=" * 70)
print("ë²„ì „ ì •ë³´ ìƒì„± ì™„ë£Œ!")
print("=" * 70)
print(f"\nğŸ“¦ ë²„ì „: {version_info['version']}")
print(f"ğŸ“… ìƒì„±ì¼ì‹œ: {version_info['created_at']}")
print(f"\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„")
print(f"  ì „ì²´ ìƒ˜í”Œ: {version_info['quality_metrics'].get('total_samples', 0):,}ê°œ")
print(f"  ë¹„ë””ì˜¤ íŒŒì¼: {preprocessed_stats['video']['count']:,}ê°œ")
print(f"  ì´ë¯¸ì§€ íŒŒì¼: {preprocessed_stats['image']['count']:,}ê°œ")
print(f"  ì´ ìš©ëŸ‰: {version_info['preprocessing']['total_size_gb']:.2f} GB")

print(f"\nğŸ¯ í’ˆì§ˆ ì§€í‘œ")
print(f"  COT ì»¤ë²„ë¦¬ì§€: {version_info['quality_metrics'].get('cot_coverage', 0):.1f}%")
print(f"  ì™„ì „í•œ COT: {version_info['quality_metrics'].get('complete_cot_rate', 0):.1f}%")
print(f"  RAPA í†µê³¼ìœ¨: {version_info['quality_metrics'].get('rapa_pass_rate', 0):.1f}%")

print(f"\nğŸ”§ Git ì •ë³´")
print(f"  ë¸Œëœì¹˜: {git_info['branch']}")
print(f"  ì»¤ë°‹: {git_info['commit'][:8]}")

print(f"\nâœ… í•™ìŠµ ì¤€ë¹„: {'ì™„ë£Œ' if version_info['training_ready'] else 'ì§„í–‰ì¤‘'}")

print(f"\nğŸ’¾ ë²„ì „ íŒŒì¼: {VERSION_FILE}")
print("=" * 70)
