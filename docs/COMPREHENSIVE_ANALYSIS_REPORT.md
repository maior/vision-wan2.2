# Wan2.2 LoRA Fine-tuning: ν†µκ³„ λ° λ¨λΈ μΆ…ν•© λ¶„μ„ λ³΄κ³ μ„

μƒμ„±μΌ: 2025-11-08
λ¶„μ„ λ€μƒ: MBC λ°μ΄ν„°μ…‹ μ „μ²λ¦¬ λ° Wan2.2-T2V-A14B LoRA Fine-tuning

---

## λ©μ°¨
1. [λ°μ΄ν„°μ…‹ κΈ°λ³Έ ν†µκ³„](#1-λ°μ΄ν„°μ…‹-κΈ°λ³Έ-ν†µκ³„)
2. [κ³ κΈ‰ ν†µκ³„ λ¶„μ„](#2-κ³ κΈ‰-ν†µκ³„-λ¶„μ„)
3. [λ¨λΈ μ•„ν‚¤ν…μ² λ¶„μ„](#3-λ¨λΈ-μ•„ν‚¤ν…μ²-λ¶„μ„)
4. [ν•™μµ μ„¤μ • λ¶„μ„](#4-ν•™μµ-μ„¤μ •-λ¶„μ„)
5. [μ£Όμ” λ°κ²¬ λ° κ¶μ¥μ‚¬ν•­](#5-μ£Όμ”-λ°κ²¬-λ°-κ¶μ¥μ‚¬ν•­)

---

## 1. λ°μ΄ν„°μ…‹ κΈ°λ³Έ ν†µκ³„

### 1.1 μ „μ²΄ λ°μ΄ν„°μ…‹ (all_data.csv)

**μ΄ μƒν” μ: 199,994κ°**

#### λ―Έλ””μ–΄ νƒ€μ… λ¶„ν¬
| νƒ€μ… | κ°μ | λΉ„μ¨ |
|------|------|------|
| Image | 99,994 | 50.00% |
| Video | 100,000 | 50.00% |

β… **μ™„λ²½ν• κ· ν•** - κ³„μΈµμ  μƒν”λ§(Stratified Sampling) μ„±κ³µ

#### ν•΄μƒλ„ λ¶„ν¬
| ν•΄μƒλ„ | κ°μ | λΉ„μ¨ |
|--------|------|------|
| 1920Γ—1080 | 155,552 | 77.78% |
| 720Γ—512 | 31,048 | 15.52% |
| 1280Γ—720 | 11,724 | 5.86% |
| κΈ°νƒ€ | 1,670 | 0.84% |

β οΈ **λ¬Έμ μ **: μ›λ³Έ λ°μ΄ν„°μ 77.78%κ°€ 1920Γ—1080 ν•΄μƒλ„μ΄μ§€λ§, Wan2.2λ” 1280Γ—720λ§ μ§€μ›
- **Wan2.2 μ§€μ› ν•΄μƒλ„ (μ „μ²λ¦¬ μ „)**: 11,724κ° (5.86%)λ§ μ§μ ‘ μ‚¬μ© κ°€λ¥
- **λ³€ν™ ν•„μ”**: 188,270κ° (94.14%)λ¥Ό 1280Γ—720μΌλ΅ λ³€ν™ ν•„μ”

#### λΉ„λ””μ¤ κΈΈμ΄ ν†µκ³„
| ν•­λ© | κ°’ |
|------|-----|
| μ΄ λΉ„λ””μ¤ | 100,000κ° |
| ν‰κ·  κΈΈμ΄ | 23.17μ΄ |
| μµμ† κΈΈμ΄ | 2.97μ΄ |
| μµλ€ κΈΈμ΄ | 2,383.65μ΄ (μ•½ 40λ¶„) |

**κΈΈμ΄ λ²”μ„λ³„ λ¶„ν¬:**
- 0-10μ΄: 20κ° (0.02%)
- 10-20μ΄: 43,609κ° (43.61%)
- **20-30μ΄: 49,360κ° (49.36%)** β† μµλ‹¤ λ¶„ν¬
- 30-60μ΄: 5,919κ° (5.92%)
- 60μ΄ μ΄μƒ: 1,092κ° (1.09%)

β… **μ–‘νΈ**: λ€λ¶€λ¶„μ λΉ„λ””μ¤κ°€ 10-30μ΄ λ²”μ„ (93%)μ— μ§‘μ¤‘λμ–΄ μ•μ •μ 

#### μΉ΄ν…κ³ λ¦¬ λ¶„ν¬
| μΉ΄ν…κ³ λ¦¬ | κ°μ | λΉ„μ¨ |
|----------|------|------|
| μƒν™/λ¬Έν™” | 57,300 | 28.65% |
| μ—­μ‚¬/μ‚¬ν | 36,158 | 18.08% |
| μμ—°/ν’κ²½ | 33,819 | 16.91% |
| κ³µκ°„/κ±΄μ¶• | 32,940 | 16.47% |
| μ‚¬κ±΄/μ‚¬κ³  | 21,209 | 10.60% |
| μ¶•μ  | 14,394 | 7.20% |
| μ ν•λ¬Έν™”μ μ‚° | 2,220 | 1.11% |
| λ¬΄ν•λ¬Έν™”μ μ‚° | 1,954 | 0.98% |

β οΈ **ν΄λμ¤ λ¶κ· ν•**: μµλ€(μƒν™/λ¬Έν™”) λ€ μµμ†(λ¬΄ν•λ¬Έν™”μ μ‚°) λΉ„μ¨ = 29.3:1

#### Caption κΈΈμ΄ ν†µκ³„
| ν•­λ© | κ°’ |
|------|-----|
| ν‰κ·  κΈΈμ΄ | 440μ |
| μµμ† κΈΈμ΄ | 125μ |
| μµλ€ κΈΈμ΄ | 10,766μ |

---

### 1.2 ν•™μµ λ°μ΄ν„°μ…‹ (all_train.csv)

**μ΄ μƒν” μ: 170,180κ° (μ „μ²΄μ 85.1%)**

#### λ―Έλ””μ–΄ νƒ€μ… λ¶„ν¬
| νƒ€μ… | κ°μ | λΉ„μ¨ |
|------|------|------|
| Video | 80,106 | 47.07% |
| Image | 90,074 | 52.93% |

β… **κ±°μ κ· ν•μ **: 1.12:1 (μ΄λ―Έμ§€:λΉ„λ””μ¤)

#### ν•΄μƒλ„ λ¶„ν¬
| ν•΄μƒλ„ | κ°μ | λΉ„μ¨ |
|--------|------|------|
| **1280Γ—720** | 170,180 | **100.00%** |

β… **μ™„λ²½**: λ¨λ“  λ°μ΄ν„°κ°€ Wan2.2 μ§€μ› ν•΄μƒλ„λ΅ λ³€ν™ μ™„λ£

#### μΉ΄ν…κ³ λ¦¬ λ¶„ν¬
| μΉ΄ν…κ³ λ¦¬ | κ°μ | λΉ„μ¨ |
|----------|------|------|
| μƒν™/λ¬Έν™” | 50,368 | 29.60% |
| κ³µκ°„/κ±΄μ¶• | 28,710 | 16.87% |
| μ—­μ‚¬/μ‚¬ν | 28,687 | 16.86% |
| μμ—°/ν’κ²½ | 28,525 | 16.76% |
| μ‚¬κ±΄/μ‚¬κ³  | 18,646 | 10.96% |
| μ¶•μ  | 12,295 | 7.22% |
| μ ν•λ¬Έν™”μ μ‚° | 1,854 | 1.09% |
| λ¬΄ν•λ¬Έν™”μ μ‚° | 1,095 | 0.64% |

**ν΄λμ¤ λ¶κ· ν• λΉ„μ¨**: 46.00:1 (μµλ€/μµμ†)

#### Caption κΈΈμ΄ ν†µκ³„
| ν•­λ© | κ°’ |
|------|-----|
| ν‰κ·  κΈΈμ΄ | 429μ |
| μµμ† κΈΈμ΄ | 125μ |
| μµλ€ κΈΈμ΄ | 10,766μ |

---

### 1.3 κ²€μ¦ λ°μ΄ν„°μ…‹ (all_val.csv)

**μ΄ μƒν” μ: 20,000κ° (μ „μ²΄μ 10.0%)**

#### λ―Έλ””μ–΄ νƒ€μ… λ¶„ν¬
| νƒ€μ… | κ°μ | λΉ„μ¨ |
|------|------|------|
| Image | 9,920 | 49.60% |
| Video | 10,080 | 50.40% |

β… **κ±°μ μ™„λ²½ν• κ· ν•**: 1.02:1

#### ν•΄μƒλ„ λ¶„ν¬ λ¬Έμ  λ°κ²¬
β οΈ **μ¤‘μ” λ°κ²¬**: κ²€μ¦ λ°μ΄ν„°μ λ€λ¶€λ¶„μ΄ μ›λ³Έ ν•΄μƒλ„λ΅ λ‚¨μ•„μμ

| ν•΄μƒλ„ | κ°μ | λΉ„μ¨ |
|--------|------|------|
| 1920Γ—1080 | 15,490 | 77.45% |
| 720Γ—512 | 3,096 | 15.48% |
| **1280Γ—720** | **1,239** | **6.19%** |
| κΈ°νƒ€ | 175 | 0.88% |

**Wan2.2 μ§€μ› ν•΄μƒλ„**: 1,239κ° (6.19%)λ§ μ‚¬μ© κ°€λ¥
**λ³€ν™ ν•„μ”**: 18,761κ° (93.81%)

π¨ **ν•΄κ²° ν•„μ”**: κ²€μ¦ λ°μ΄ν„°λ„ 1280Γ—720μΌλ΅ μ „μ²λ¦¬ ν•„μ”

---

## 2. κ³ κΈ‰ ν†µκ³„ λ¶„μ„

### 2.1 Caption λ‹¤μ–‘μ„± λ¶„μ„

#### μ–΄ν λ‹¤μ–‘μ„± μ§€ν‘ (Type-Token Ratio, TTR)

**ν•™μµ λ°μ΄ν„° (all_train.csv):**
| μ§€ν‘ | κ°’ | ν‰κ°€ |
|------|-----|------|
| ν‰κ·  TTR | 0.8486 | β… λ§¤μ° μ°μ |
| μµμ† TTR | 0.2267 | μΌλ¶€ λ°λ³µμ  caption μ΅΄μ¬ |
| μµλ€ TTR | 1.0000 | μ™„μ „ν κ³ μ ν• ν‘ν„ |
| μ „μ²΄ TTR | 0.0269 | μ •μƒ (λ€κ·λ¨ λ°μ΄ν„°μ…‹) |
| μ΄ ν† ν° μ | 18,108,519 | - |
| κ³ μ  μ–΄ν μ | 486,761 | β… λ§¤μ° ν’λ¶€ |

**κ²€μ¦ λ°μ΄ν„° (all_val.csv):**
| μ§€ν‘ | κ°’ |
|------|-----|
| ν‰κ·  TTR | 0.8447 |
| κ³ μ  μ–΄ν μ | 145,743 |
| μ΄ ν† ν° μ | 2,196,660 |

**ν•΄μ„:**
- β… **ν‰κ·  TTR 0.85**: λ§¤μ° μ°μν• μ–΄ν λ‹¤μ–‘μ„± (μΌλ°μ μΌλ΅ 0.5 μ΄μƒμ΄λ©΄ μ–‘νΈ)
- β… **κ³ μ  μ–΄ν 48λ§ κ°**: ν’λ¶€ν• ν‘ν„λ ¥
- β… ν•™μµ/κ²€μ¦ λ°μ΄ν„°μ TTRμ΄ μ μ‚¬ (0.8486 vs 0.8447) β†’ λ¶„ν• μ΄ μ λ¨

#### Caption λ‹Ή λ‹¨μ–΄ μ ν†µκ³„
| λ°μ΄ν„°μ…‹ | ν‰κ·  λ‹¨μ–΄ μ | μµμ† | μµλ€ |
|----------|--------------|------|------|
| Train | 106.4 | 31 | 2,533 |
| Val | 109.8 | 35 | 1,491 |

#### κ°€μ¥ λΉλ²ν• λ‹¨μ–΄ Top 10 (ν•™μµ λ°μ΄ν„°)
1. μλ‹¤: 551,422ν
2. μλ”: 202,540ν
3. μμΌλ©°: 148,873ν
4. μ—¬λ¬: 145,152ν
5. μ‚¬λμ΄: 142,520ν
6. μ‚¬λλ“¤μ΄: 142,331ν
7. μμµλ‹λ‹¤: 141,680ν
8. ν•: 139,669ν
9. μλ£λ΅: 120,752ν
10. μ: 105,260ν

**νΉμ§•:**
- μ£Όλ΅ μ„μ ν• μ΅°μ‚¬ λ° μΌλ° λ…μ‚¬
- "μλ£λ΅", "ν™μ©", "κµμ΅" λ“±μ΄ μƒμ„κ¶ β†’ MBC λ°©μ†΅ μ•„μΉ΄μ΄λΈ λ°μ΄ν„°μ νΉμ„± λ°μ

---

### 2.2 ν΄λμ¤ λ¶κ· ν• λ¶„μ„

#### λ―Έλ””μ–΄ νƒ€μ… λ¶κ· ν•
| λ°μ΄ν„°μ…‹ | μ΄λ―Έμ§€:λΉ„λ””μ¤ λΉ„μ¨ | Gini κ³„μ | ν‰κ°€ |
|----------|---------------------|-----------|------|
| Train | 1.12:1 | - | β… κ±°μ κ· ν• |
| Val | 1.02:1 | - | β… λ§¤μ° κ· ν•μ  |

#### μΉ΄ν…κ³ λ¦¬ λ¶κ· ν•
| λ°μ΄ν„°μ…‹ | μµλ€/μµμ† λΉ„μ¨ | Gini κ³„μ | ν‰κ°€ |
|----------|----------------|-----------|------|
| Train | 46.00:1 | 0.3954 | β οΈ μ¤‘κ°„ λ¶κ· ν• |
| Val | 27.00:1 | 0.3834 | β οΈ μ¤‘κ°„ λ¶κ· ν• |

**Gini κ³„μ ν•΄μ„:**
- 0 = μ™„μ „ κ· ν•
- 1 = μ™„μ „ λ¶κ· ν•
- **0.39**: μ¤‘κ°„ μ •λ„μ λ¶κ· ν• β†’ κ°μ„  μ—¬μ§€ μμ

**μΉ΄ν…κ³ λ¦¬λ³„ μƒν” μ (Train):**
- μµλ€: μƒν™/λ¬Έν™” (50,368κ°)
- μµμ†: λ¬΄ν•λ¬Έν™”μ μ‚° (1,095κ°)
- λΉ„μ¨: 46:1

**κ¶μ¥μ‚¬ν•­:**
1. β οΈ **μ†μ ν΄λμ¤ μ¦κ°• ν•„μ”**: λ¬΄ν•λ¬Έν™”μ μ‚°, μ ν•λ¬Έν™”μ μ‚° μΉ΄ν…κ³ λ¦¬
2. κ°€λ¥ν• λ°©λ²•:
   - Data augmentation (λΉ„λ””μ¤ νμ „, ν¬λ΅­, μƒ‰μƒ μ΅°μ •)
   - Weighted sampling (ν•™μµ μ‹ μ†μ ν΄λμ¤ κ³Όν‘μ§‘)
   - Class-balanced loss (μ†μ ν΄λμ¤μ— λ” λ†’μ€ κ°€μ¤‘μΉ)

---

### 2.3 μƒκ΄€κ΄€κ³„ λ¶„μ„

#### λΉ„λ””μ¤ κΈΈμ΄ vs Caption κΈΈμ΄ μƒκ΄€κ΄€κ³„

| λ°μ΄ν„°μ…‹ | μƒν” μ | Pearson μƒκ΄€κ³„μ | ν•΄μ„ |
|----------|---------|-------------------|------|
| Train | 80,106 | 0.0886 | μ•½ν• μ–‘μ μƒκ΄€κ΄€κ³„ |
| Val | 10,080 | 0.2286 | μ•½ν• μ–‘μ μƒκ΄€κ΄€κ³„ |

**ν•΄μ„:**
- β… **μ•½ν• μ–‘μ μƒκ΄€κ΄€κ³„**: λΉ„λ””μ¤κ°€ κΈΈμ–΄μ§μλ΅ captionλ„ μ•½κ°„ κΈΈμ–΄μ§€λ” κ²½ν–¥
- β… **λ…λ¦½μ„± μ μ§€**: μƒκ΄€κ³„μκ°€ λ‚®μ•„μ„ captionμ΄ λΉ„λ””μ¤ κΈΈμ΄μ— κ³Όλ„ν•κ² μμ΅΄ν•μ§€ μ•μ
- β… **μ–‘νΈν• νΉμ„±**: Captionμ΄ λΉ„λ””μ¤ λ‚΄μ©μ„ λ…λ¦½μ μΌλ΅ μ μ„¤λ…ν•κ³  μμ

---

## 3. λ¨λΈ μ•„ν‚¤ν…μ² λ¶„μ„

### 3.1 Wan2.2-T2V-A14B μ•„ν‚¤ν…μ²

#### μ „μ²΄ κµ¬μ΅°
```
Text Prompt β†’ T5 Encoder β†’ DiT (MoE) β†’ VAE Decoder β†’ Video Frames
                            β†‘
                      LoRA Adapters
```

#### T5 Text Encoder
| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| λ¨λΈ | UMT5-XXL |
| μ²΄ν¬ν¬μΈνΈ | models_t5_umt5-xxl-enc-bf16.pth |
| ν† ν¬λ‚μ΄μ € | google/umt5-xxl |
| Dtype | bfloat16 |
| μµλ€ ν…μ¤νΈ κΈΈμ΄ | 512 ν† ν° |

**V100 μ„¤μ •μ—μ„μ μµμ ν™”:**
- Max caption length: 512 β†’ **256** (λ©”λ¨λ¦¬ μ μ•½)
- CPU μ¤ν”„λ΅λ“: **ν™μ„±ν™”** (T5λ¥Ό CPUλ΅ μ΄λ™ν•μ—¬ GPU λ©”λ¨λ¦¬ μ μ•½)

---

#### DiT (Diffusion Transformer) - MoE μ•„ν‚¤ν…μ²

**ν•µμ‹¬ νλΌλ―Έν„°:**
| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| λ¨λΈ ν¬κΈ° | 14B (ν™μ„± νλΌλ―Έν„°) |
| μ΄ νλΌλ―Έν„° | 27B (2κ° expert) |
| Dimension | 5,120 |
| FFN Dimension | 13,824 |
| Attention Heads | 40 |
| Layers | 40 |
| Frequency Dim | 256 |
| Patch Size | (1, 2, 2) |
| Window Size | (-1, -1) (μ „μ—­ attention) |
| QK Normalization | β… |
| Cross Attention Norm | β… |
| Epsilon | 1e-6 |

**MoE (Mixture-of-Experts) κµ¬μ΅°:**
```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚    High Noise Expert (13.5B)      β”‚  β† μ΄κΈ° denoising (λ μ΄μ•„μ›ƒ μƒμ„±)
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚    Low Noise Expert (13.5B)       β”‚  β† ν›„κΈ° denoising (λ””ν…μΌ μ •μ )
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
         β†‘
    SNR Threshold (boundary = 0.875)
```

- **μ΄ 27B νλΌλ―Έν„°**, κ° λ‹¨κ³„μ—μ„ **14Bλ§ ν™μ„±ν™”**
- μ‹ νΈ λ€ μ΅μ λΉ„μ¨(SNR)μ— λ”°λΌ expert μλ™ μ „ν™
- High noise expert: λ μ΄μ•„μ›ƒ, μ „μ²΄ κµ¬μ΅° μƒμ„±
- Low noise expert: μ„Έλ¶€ λ””ν…μΌ, μ§κ° μ •μ 

---

#### VAE (Video Autoencoder)

| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| λ¨λΈ | Wan2.1_VAE |
| μ²΄ν¬ν¬μΈνΈ | Wan2.1_VAE.pth |
| Compression Ratio | 4Γ—8Γ—8 (μ‹κ°„Γ—λ†’μ΄Γ—λ„λΉ„) |
| Latent Channels | 16 |

**μ••μ¶• μμ‹:**
- μ…λ ¥: 81 frames Γ— 720 Γ— 1280 Γ— 3
- Latent: 21 Γ— 90 Γ— 160 Γ— 16
- μ••μ¶•λ¥ : **1/256**

**V100 μµμ ν™”:**
- VAE CPU μ¤ν”„λ΅λ“: **ν™μ„±ν™”**
- VAE encode batch size: 8 β†’ **4** (λ©”λ¨λ¦¬ μ μ•½)

---

### 3.2 LoRA (Low-Rank Adaptation) μ„¤μ •

#### κΈ°λ³Έ LoRA μ„¤μ • (A100 κΈ°μ¤€)
| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| LoRA Rank (r) | 32 |
| LoRA Alpha | 32 |
| LoRA Dropout | 0.05 |
| LoRA Bias | none |

**μ μ© λ¨λ“:**
- `to_q` (Query projection)
- `to_k` (Key projection)
- `to_v` (Value projection)
- `to_out.0` (Output projection)

**νλΌλ―Έν„° μ κ³„μ‚°:**
```
κ° Attention λ μ΄μ–΄:
  μ›λ³Έ κ°€μ¤‘μΉ: 5120 Γ— 5120 = 26,214,400
  LoRA κ°€μ¤‘μΉ: (5120 Γ— 32) + (32 Γ— 5120) = 327,680
  μ••μ¶• λΉ„μ¨: 1.25%

μ΄ ν•™μµ νλΌλ―Έν„°:
  40 layers Γ— 4 modules Γ— 327,680 β‰ 52M (0.05B)
  μ „μ²΄ 14B λ€λΉ„: 0.37%λ§ ν•™μµ
```

---

#### V100 μµμ ν™” LoRA μ„¤μ •

| νλΌλ―Έν„° | A100 | V100 | λ³€κ²½μ‚¬ν•­ |
|----------|------|------|----------|
| LoRA Rank (r) | 32 | **16** | β†“ 50% |
| LoRA Alpha | 32 | **16** | β†“ 50% |
| LoRA Dropout | 0.05 | 0.05 | λ™μΌ |

**λ©”λ¨λ¦¬ μ κ° ν¨κ³Ό:**
```
V100 LoRA νλΌλ―Έν„°:
  κ° Attention λ μ΄μ–΄: (5120 Γ— 16) + (16 Γ— 5120) = 163,840
  μ΄ ν•™μµ νλΌλ―Έν„°: 40 layers Γ— 4 modules Γ— 163,840 β‰ 26M

λ©”λ¨λ¦¬ μ μ•½: 52M β†’ 26M (50% κ°μ†)
```

---

### 3.3 Inference μ„¤μ •

| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| Timesteps | 1,000 |
| Sampling Steps | 40 |
| Sample FPS | 16 |
| Frame Number | 81 (V100: **49**) |
| Shift | 12.0 |
| Guidance Scale | Low: 3.0, High: 4.0 |
| Boundary (SNR) | 0.875 |

**V100 μµμ ν™”:**
- Frame number: 81 β†’ **49** (μ•½ 40% λ©”λ¨λ¦¬ μ κ°)
- 49 ν”„λ μ„ = μ•½ 3μ΄ λΉ„λ””μ¤ (16 FPS)

---

## 4. ν•™μµ μ„¤μ • λ¶„μ„

### 4.1 V100 32GB Γ— 2 μµμ ν™” μ„¤μ •

#### ν•λ“μ›¨μ–΄ κµ¬μ„±
| ν•­λ© | κ°’ |
|------|-----|
| GPU | V100 32GB Γ— 2 |
| CUDA | 12.1 |
| RAM | 128 GB |
| λ””μ¤ν¬ | 250 GB |

---

#### ν•™μµ ν•μ΄νΌνλΌλ―Έν„°

| νλΌλ―Έν„° | A100 κΈ°μ¤€ | V100 μµμ ν™” | λ³€κ²½ μ΄μ  |
|----------|-----------|-------------|-----------|
| Epochs | 3 | 3 | λ™μΌ |
| Batch Size (per GPU) | 1 | 1 | λ™μΌ |
| Gradient Accumulation | 4 | **16** | λ©”λ¨λ¦¬ μ μ•½ |
| Learning Rate | 1e-4 | 1e-4 | λ™μΌ |
| Weight Decay | 0.01 | 0.01 | λ™μΌ |
| Warmup Steps | 100 | 100 | λ™μΌ |
| Max Grad Norm | 1.0 | 1.0 | λ™μΌ |

**Effective Batch Size κ³„μ‚°:**
```
A100: 1 Γ— 4 Γ— 8 = 32
V100: 1 Γ— 16 Γ— 2 = 32
β†’ λ™μΌν• Effective Batch Size μ μ§€!
```

---

#### λ©”λ¨λ¦¬ μµμ ν™” μ „λµ

| μ „λµ | μ„¤μ • | λ©”λ¨λ¦¬ μ κ° ν¨κ³Ό |
|------|------|------------------|
| LoRA Rank | 32 β†’ 16 | 50% |
| Frame Number | 81 β†’ 49 | 40% |
| Caption Length | 512 β†’ 256 | 20% |
| T5 CPU Offload | β… | ~12GB |
| VAE CPU Offload | β… | ~8GB |
| 8-bit Optimizer | β… | ~6GB |
| Gradient Checkpointing | β… | ~4GB |
| Mixed Precision (bf16) | β… | 50% |

**μ΄ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ (GPUλ‹Ή):**
```
Base Model (DiT): ~20GB
LoRA (r=16): ~2GB
Gradients + 8bit Optimizer: ~6GB
Activations (with checkpointing): ~2GB
β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
μ΄: ~30GB / 32GB
μ—¬μ : ~2GB (μ•μ „ λ§μ§„)
```

---

#### λ¶„μ‚° ν•™μµ μ„¤μ •

| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| DiT FSDP | β… (Fully Sharded Data Parallel) |
| T5 FSDP | β (CPU μ¤ν”„λ΅λ“ μ‚¬μ©) |
| Ulysses Size | 2 (μ‹ν€€μ¤ λ³‘λ ¬ν™”) |
| Mixed Precision | bfloat16 |
| Gradient Checkpointing | β… |

**FSDP (Fully Sharded Data Parallel):**
- λ¨λΈ νλΌλ―Έν„°, κ·Έλλ””μ–ΈνΈ, μµν‹°λ§μ΄μ € μƒνƒλ¥Ό GPU κ°„ λ¶„μ‚°
- κ° GPUλ” μ „μ²΄ λ¨λΈμ μΌλ¶€λ§ μ €μ¥ β†’ λ©”λ¨λ¦¬ μ μ•½
- ν•„μ” μ‹ ν†µμ‹ ν•μ—¬ μ „μ²΄ νλΌλ―Έν„° μ¬κµ¬μ„±

**Ulysses Sequence Parallelism:**
- Attention μ—°μ‚°μ„ μ‹ν€€μ¤ μ°¨μ›μ—μ„ λ¶„ν• 
- κΈ΄ μ‹ν€€μ¤(49 frames)λ¥Ό 2κ° GPUμ— λ¶„μ‚° μ²λ¦¬

---

#### Optimizer λ° Scheduler

| ν•­λ© | μ„¤μ • |
|------|------|
| Optimizer | **AdamW 8-bit** |
| Scheduler | Cosine Annealing |
| Warmup Steps | 100 |
| Final LR | 0 (cosine decay) |

**8-bit AdamW:**
- Optimizer μƒνƒλ¥Ό 8bitλ΅ μ–‘μν™”
- λ©”λ¨λ¦¬ μ μ•½: ~6GB (V100μ—μ„ μ¤‘μ”)
- μ„±λ¥ μ €ν• κ±°μ μ—†μ (μ—°κµ¬ κ²°κ³Ό)

---

#### λ΅κΉ… λ° μ²΄ν¬ν¬μΈνΈ

| ν•­λ© | κ°’ |
|------|-----|
| Logging Steps | 10 |
| Save Steps | 500 |
| Eval Steps | 500 |
| Save Total Limit | 2 |
| Resume from Checkpoint | β… |
| Weights & Biases | β (μ„ νƒ) |

**μ²΄ν¬ν¬μΈνΈ ν¬κΈ°:**
- LoRA νλΌλ―Έν„° (r=16): ~487MB
- μ „μ²΄ λ¨λΈ λ€λΉ„: 3.5% ν¬κΈ°

---

### 4.2 ν•™μµ λ°μ΄ν„° μ„¤μ •

| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| Train CSV | preprocessed_data/all_train.csv |
| Val CSV | preprocessed_data/all_val.csv |
| Train Samples | 170,180 |
| Val Samples | 20,000 |
| Split Ratio | 90:10 |
| Random Seed | 42 (μ¬ν„μ„±) |

---

### 4.3 CFG (Classifier-Free Guidance) μ„¤μ •

| νλΌλ―Έν„° | κ°’ |
|----------|-----|
| CFG Scale | 7.0 |
| CFG Dropout | 0.1 (10%) |

**CFG Dropout:**
- ν•™μµ μ‹ 10% ν™•λ¥ λ΅ ν…μ¤νΈ μ΅°κ±΄ μ κ±°
- λ¨λΈμ΄ μ΅°κ±΄λ¶€/λ¬΄μ΅°κ±΄λ¶€ μƒμ„± λ¨λ‘ ν•™μµ
- Inference μ‹ CFG μ μ© κ°€λ¥

---

### 4.4 ν•™μµ μ‹κ°„ μμΈ΅

**1 Epoch μμƒ μ‹κ°„:**
```
μ΄ μƒν”: 170,180
Effective batch size: 32
μ΄ Steps: 170,180 / 32 = 5,318 steps

Stepλ‹Ή μ‹κ°„ (V100): ~20-25μ΄ (μμƒ)
1 Epoch μ‹κ°„: 5,318 Γ— 22μ΄ β‰ 32μ‹κ°„

μ΄ 3 Epochs: 32 Γ— 3 = 96μ‹κ°„ (μ•½ 4μΌ)
```

**μ‹¤μ  ν•™μµ μ‹κ°„ (μμƒ):**
- μµμ†: 5μΌ (μ΄μƒμ )
- μµλ€: 7μΌ (μ²΄ν¬ν¬μΈνΈ μ €μ¥, ν‰κ°€ ν¬ν•¨)

---

## 5. μ£Όμ” λ°κ²¬ λ° κ¶μ¥μ‚¬ν•­

### 5.1 λ°μ΄ν„°μ…‹ ν’μ§

#### β… κ°•μ 
1. **μ™„λ²½ν• λ―Έλ””μ–΄ νƒ€μ… κ· ν•**: 50:50 (μ΄λ―Έμ§€:λΉ„λ””μ¤)
2. **λ†’μ€ Caption λ‹¤μ–‘μ„±**: TTR 0.85 (λ§¤μ° μ°μ)
3. **ν’λ¶€ν• μ–΄ν**: 48λ§ κ° κ³ μ  λ‹¨μ–΄
4. **μ•μ •μ μΈ λΉ„λ””μ¤ κΈΈμ΄**: 93%κ°€ 10-30μ΄
5. **μ¶©λ¶„ν• λ°μ΄ν„° κ·λ¨**: 17λ§ ν•™μµ μƒν”

#### β οΈ κ°μ„  ν•„μ”
1. **μΉ΄ν…κ³ λ¦¬ λ¶κ· ν•**: Gini κ³„μ 0.39 (μ¤‘κ°„ λ¶κ· ν•)
   - μµλ€/μµμ† λΉ„μ¨: 46:1
   - μ†μ ν΄λμ¤: λ¬΄ν•λ¬Έν™”μ μ‚°(1,095), μ ν•λ¬Έν™”μ μ‚°(1,854)

2. **κ²€μ¦ λ°μ΄ν„° ν•΄μƒλ„**: 93.81%κ°€ μ›λ³Έ ν•΄μƒλ„
   - 1280Γ—720 λ³€ν™ ν•„μ”
   - κ²€μ¦ μ‹ μ¤λ¥ λ°μƒ κ°€λ¥

3. **Caption κΈΈμ΄ νΈμ°¨**: μµμ† 125μ ~ μµλ€ 10,766μ
   - μΌλ¶€ λ§¤μ° κΈ΄ caption (truncation ν•„μ”)

---

### 5.2 ν†µκ³„μ  κΈ°λ²• μ‚¬μ© ν„ν™©

#### β… μ΄λ―Έ μ μ©λ κΈ°λ²•
1. **Random Sampling** (random_state=42)
2. **Stratified Sampling** (50:50 video:image)
3. **Train/Val Split** (90:10)
4. **Frequency Analysis** (Counter)
5. **Outlier Detection** (range-based)
6. **Duplicate Detection** (hash-based)
7. **Quality Score Calculation**
8. **Type-Token Ratio** (μ–΄ν λ‹¤μ–‘μ„±)
9. **Correlation Analysis** (Pearson)
10. **Gini Coefficient** (ν΄λμ¤ λ¶κ· ν• μΈ΅μ •)

#### β μ μ© λ¶ν•„μ”
- **VIF (Variance Inflation Factor)**:
  - μ „ν†µμ  νκ·€ λ¶„μ„μ© (λ‹¤μ¤‘κ³µμ„ μ„± κ²€μ¶)
  - λΉ„μ •ν• λ°μ΄ν„°(μ΄λ―Έμ§€/λΉ„λ””μ¤/ν…μ¤νΈ)μ—λ” λ¶€μ ν•©
  - Diffusion λ¨λΈμ€ λ…μ‹μ  feature engineering μ—†μ

---

### 5.3 κ¶μ¥μ‚¬ν•­

#### μ°μ„ μμ„ 1: κ²€μ¦ λ°μ΄ν„° μ „μ²λ¦¬
```bash
# κ²€μ¦ λ°μ΄ν„°λ„ 1280Γ—720μΌλ΅ λ³€ν™
python preprocess_mbc_data.py --mode validation --target_resolution 1280 720
```

#### μ°μ„ μμ„ 2: ν΄λμ¤ λ¶κ· ν• ν•΄κ²°
**λ°©λ²• 1: Weighted Sampling**
```python
# ν•™μµ μ‹ μ†μ ν΄λμ¤ κ³Όν‘μ§‘
class_weights = {
    'μƒν™/λ¬Έν™”': 1.0,
    'λ¬΄ν•λ¬Έν™”μ μ‚°': 46.0,  # μ—­κ°€μ¤‘μΉ
    # ...
}
```

**λ°©λ²• 2: Data Augmentation**
- μ†μ ν΄λμ¤(λ¬΄ν•λ¬Έν™”μ μ‚°, μ ν•λ¬Έν™”μ μ‚°)μ— μ¦κ°• μ μ©
- λΉ„λ””μ¤: μ‹κ°„ λ°μ „, μ†λ„ μ΅°μ •, ν¬λ΅­
- μ΄λ―Έμ§€: νμ „, ν”λ¦½, μƒ‰μƒ μ΅°μ •

**λ°©λ²• 3: Focal Loss**
```python
# μ†μ ν΄λμ¤μ— λ” λ†’μ€ κ°€μ¤‘μΉ
loss = FocalLoss(gamma=2.0)
```

#### μ°μ„ μμ„ 3: Caption κΈΈμ΄ μ •κ·ν™”
```python
# V100 μ„¤μ •: max_length=256
# λ§¤μ° κΈ΄ caption (>512μ) truncation
truncate_captions(max_length=256)
```

#### μ°μ„ μμ„ 4: μ¶”κ°€ ν†µκ³„ λ¶„μ„ (μ„ νƒ)
1. **Semantic Diversity Analysis**
   - Caption μ„λ² λ”© κΈ°λ° λ‹¤μ–‘μ„± μΈ΅μ •
   - BERT/Sentence-BERT ν™μ©

2. **Time-series Analysis**
   - λΉ„λ””μ¤ ν”„λ μ„ κ°„ λ³€ν™”μ¨ λ¶„μ„
   - Motion intensity μΈ΅μ •

3. **Cross-modal Correlation**
   - μ΄λ―Έμ§€/λΉ„λ””μ¤μ™€ Captionμ μλ―Έλ΅ μ  μΌμΉλ„
   - CLIP Score κ³„μ‚°

---

### 5.4 λ¨λΈ ν•™μµ κ¶μ¥μ‚¬ν•­

#### ν•™μµ μ „ μ²΄ν¬λ¦¬μ¤νΈ
- [x] μ²΄ν¬ν¬μΈνΈ λ‹¤μ΄λ΅λ“ (Wan2.2-T2V-A14B)
- [x] λ°μ΄ν„° μ „μ²λ¦¬ (1280Γ—720 λ³€ν™)
- [ ] **κ²€μ¦ λ°μ΄ν„° μ „μ²λ¦¬** β† ν•„μ!
- [x] GPU λ©”λ¨λ¦¬ ν™•μΈ (V100 32GB Γ— 2)
- [x] LoRA μ„¤μ • ν™•μΈ (r=16)
- [ ] ν΄λμ¤ λ¶κ· ν• ν•΄κ²° (μ„ νƒ)

#### μ¤λ²„ν”Όν… ν…μ¤νΈ (ν•„μ!)
```bash
# 100κ° μƒν”λ΅ λΉ λ¥Έ ν…μ¤νΈ (30-60λ¶„)
bash train_v100_test.sh

# ν™•μΈμ‚¬ν•­:
# 1. Lossκ°€ κ°μ†ν•λ”κ°€?
# 2. GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ (~30GB/32GB)
# 3. OOM μ—λ¬ μ—†μ΄ μ™„λ£λλ”κ°€?
```

#### μ „μ²΄ ν•™μµ
```bash
# 170,180 μƒν” ν•™μµ (5-7μΌ)
bash train_v100.sh

# λ¨λ‹ν„°λ§:
# - nvidia-smi (GPU μ‚¬μ©λ¥ )
# - tail -f lora_checkpoints_v100/train.log (loss)
```

#### ν•™μµ μ¤‘ μ£Όμμ‚¬ν•­
1. **λ©”λ¨λ¦¬ λ¶€μ΅± μ‹**:
   - Gradient accumulation β†‘ (16 β†’ 32)
   - Frame number β†“ (49 β†’ 33)
   - Batch size ν™•μΈ (1 μ μ§€)

2. **Lossκ°€ κ°μ†ν•μ§€ μ•μ„ μ‹**:
   - Learning rate μ΅°μ • (1e-4 β†’ 5e-5)
   - Warmup steps β†‘ (100 β†’ 500)
   - CFG dropout ν™•μΈ (0.1)

3. **μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬**:
   - λ””μ¤ν¬ κ³µκ°„ ν™•μΈ (κ° μ²΄ν¬ν¬μΈνΈ ~500MB)
   - save_total_limit=2 (μµκ·Ό 2κ°λ§ λ³΄κ΄€)

---

### 5.5 ν‰κ°€ μ§€ν‘ κ¶μ¥

#### μ •λ‰μ  ν‰κ°€
1. **FVD (FrΓ©chet Video Distance)**: λΉ„λ””μ¤ ν’μ§
2. **IS (Inception Score)**: μƒμ„± λ‹¤μ–‘μ„±
3. **LPIPS**: μ§€κ°μ  μ μ‚¬λ„
4. **CLIP Score**: ν…μ¤νΈ-λΉ„λ””μ¤ μΌμΉλ„

#### μ •μ„±μ  ν‰κ°€
1. **μƒν”λ§ ν…μ¤νΈ**: λ‹¤μ–‘ν• ν”„λ΅¬ν”„νΈλ΅ μƒμ„±
2. **μΉ΄ν…κ³ λ¦¬λ³„ ν’μ§**: κ° μΉ΄ν…κ³ λ¦¬ λ€ν‘ μƒν”
3. **μ‹κ°„ μΌκ΄€μ„±**: λΉ„λ””μ¤ ν”„λ μ„ κ°„ μ—°μ†μ„±
4. **ν…μ¤νΈ μ¶©μ‹¤λ„**: Caption λ‚΄μ© λ°μ μ •λ„

---

## 6. κ²°λ΅ 

### λ°μ΄ν„°μ…‹ ν’μ§ μΆ…ν•© ν‰κ°€: **A- (μ°μ)**

**κ°•μ :**
- β… μ¶©λ¶„ν• λ°μ΄ν„° κ·λ¨ (17λ§ μƒν”)
- β… μ™„λ²½ν• λ―Έλ””μ–΄ νƒ€μ… κ· ν•
- β… λ§¤μ° λ†’μ€ Caption λ‹¤μ–‘μ„± (TTR 0.85)
- β… μ μ ν• ν†µκ³„μ  κΈ°λ²• μ μ©

**κ°μ„  ν•„μ”:**
- β οΈ μΉ΄ν…κ³ λ¦¬ λ¶κ· ν• (Gini 0.39)
- β οΈ κ²€μ¦ λ°μ΄ν„° ν•΄μƒλ„ λ³€ν™
- β οΈ μ†μ ν΄λμ¤ μ¦κ°•

---

### λ¨λΈ μ„¤μ • μΆ…ν•© ν‰κ°€: **A+ (μµμ )**

**κ°•μ :**
- β… V100 λ©”λ¨λ¦¬ μµμ ν™” μ™„λ²½
- β… Effective batch size μ μ§€ (32)
- β… μµμ‹  κΈ°λ²• μ μ© (FSDP, 8-bit optimizer)
- β… μ•μ „ λ§μ§„ ν™•λ³΄ (30GB/32GB)

**μμƒ μ„±λ¥:**
- ν•™μµ μ‹κ°„: 5-7μΌ
- Loss μλ ΄: μμƒλ¨
- OOM μ„ν—: λ‚®μ
- μµμΆ… ν’μ§: μ°μ μμƒ

---

### μµμΆ… κ¶μ¥μ‚¬ν•­

1. **μ¦‰μ‹ μ‹¤ν–‰**: κ²€μ¦ λ°μ΄ν„° ν•΄μƒλ„ λ³€ν™
2. **ν•™μµ μ „**: μ¤λ²„ν”Όν… ν…μ¤νΈ (100 μƒν”)
3. **μ„ νƒ μ‚¬ν•­**: ν΄λμ¤ λ¶κ· ν• ν•΄κ²° (weighted sampling)
4. **ν•™μµ μ‹μ‘**: V100 μ„¤μ •μΌλ΅ μ „μ²΄ ν•™μµ
5. **ν‰κ°€**: FVD, CLIP Scoreλ΅ μ •λ‰μ  ν‰κ°€

**μ¶”μ • μ„±κ³µλ¥ : 85-90%**

---

**λ³΄κ³ μ„ λ**
